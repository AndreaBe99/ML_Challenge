{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning 2021/2022 - Challenge \n",
    "\n",
    "<hr>\n",
    "\n",
    "# Identification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "yourNameSurname='Andrea Bernini' # e.g., yourNameSurname='Mario Rossi'\n",
    "yourMatricolaNumber='2021867' # e.g., yourMatricolaNumber='12345678'\n",
    "yourStudentEMAIL='bernini.2021867@studenti.uniroma1.it' # e.g., yourStudentEMAIL='rossim.12345678@studenti.uniroma1.it'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 1. Mandatory Rules:\n",
    "- This year the results of the challenges will count 11,2/28 of your final grade (full info about grades <a href='https://twiki.di.uniroma1.it/twiki/view/ApprAuto '>here</a>).\n",
    "- Only one submission is allowed. We will not consider multiple submissions.\n",
    "- Please remember your solution must be <b>\"YOUR SOLUTION\"</b>, hence you are requested to deliver your individual answers/arguments/opinions/critics.\n",
    "- Mail your solution (with your <b>jupyter notebook</b> and the cleaned dataset) only to stefano.faralli@uniroma1.it <b>deadlines are announced on the ML google group and <a href='https://twiki.di.uniroma1.it/twiki/view/ApprAuto'>here</a> (NO EXCEPTIONS)</b> if you miss to deliver your solution you must wait the next (if any) available deadline. \n",
    "- The subject of your email must be: \"[ML-21-22-Challenge_solution] NAME - SURNAME - MATRICOLA\".\n",
    "- Double check the subject of your email and the attachments.\n",
    "- In case you want to compress the attachment, <b>USE ONLY STANDARD ZIP compression</b> (NO RAR,7Z etc..).\n",
    "- <b>Please sumbit The notebook (with SAVED OUTPUTS) and the cleaned dataset!</b>.\n",
    "- Your solution might be considered as the \"copy\" of others solutions, in that specific case the resulting score for all involved students will be 0/8.\n",
    "- Then read carefully all the part of the jupyter notebook and fill all fields.\n",
    "- <b>solutions (and correspondig points) are evaluated mainly on your thoughts/comments/opinions</b>.  \n",
    "- If you have questions <b>Don't write \"personal\" emails</b> to Stefano Faralli, instead <b>use our google group</b>.\n",
    "- A solution having a summary discussion with less than 500 words is evaluated with 0 points.\n",
    "- Comments summary etc.. must be in <b>English</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "### Dataset and task Description:\n",
    "<img width='400' src='news-online.jpeg'/>\n",
    "\n",
    "- The challenge is about online news popularity;\n",
    "- The provided dataset consists of one single csv file (\"OnlineNewsPopularity.csv\");\n",
    "- The provided dataset is a modified <b>noisy</b> version of the original dataset described in [1];\n",
    "\n",
    "[1] K. Fernandes, P. Vinagre and P. Cortez. A Proactive Intelligent Decision\n",
    "    Support System for Predicting the Popularity of Online News. Proceedings\n",
    "    of the 17th EPIA 2015 - Portuguese Conference on Artificial Intelligence,\n",
    "    September, Coimbra, Portugal\n",
    "\n",
    "\n",
    "This dataset summarizes a heterogeneous set of features about articles published by Mashable in a period of two years. The goal of the task is to predict the number of shares in social networks (popularity).\n",
    "\n",
    "Number of Instances: <b>39,797</b> \n",
    "\n",
    "Number of Attributes: <b>61</b>\n",
    "\n",
    "Target: <b>shares</b>\n",
    "\n",
    "### Attribute Information:\n",
    "\n",
    "<table>\n",
    " <tr><th> index </th><th>name</th><th>description</th></tr>\n",
    " <tr><td>0</td><td>url</td><td>URL of the article</td></tr>\n",
    " <tr><td>1</td><td>timedelta</td><td>Days between the article publication and the dataset acquisition</td></tr>\n",
    " <tr><td>2</td><td>n_tokens_title</td><td>Number of words in the title</td></tr>\n",
    " <tr><td>3</td><td>n_tokens_content</td><td>Number of words in the content</td></tr>\n",
    " <tr><td>4</td><td>n_unique_tokens</td><td>Rate of unique words in the content</td></tr>\n",
    " <tr><td>5</td><td>n_non_stop_words</td><td>Rate of non-stop words in the content</td></tr>\n",
    " <tr><td>6</td><td>n_non_stop_unique_tokens</td><td>Rate of unique non-stop words in content</td></tr>\n",
    " <tr><td>7</td><td>num_hrefs</td><td>Number of links</td></tr>\n",
    " <tr><td>8</td><td>num_self_hrefs</td><td>Number of links to other articles published by Mashable</td></tr>\n",
    " <tr><td>9</td><td>num_imgs</td><td>Number of images</td></tr>\n",
    " <tr><td>10</td><td>num_videos</td><td>Number of videos</td></tr>\n",
    " <tr><td>11</td><td>average_token_length</td><td>Average length of the words in the content</td></tr>\n",
    " <tr><td>12</td><td>num_keywords</td><td>Number of keywords in the metadata</td></tr>\n",
    " <tr><td>13</td><td>data_channel_is_lifestyle</td><td>Is data channel 'Lifestyle'?</td></tr>\n",
    " <tr><td>14</td><td>data_channel_is_entertainment</td><td>Is data channel 'Entertainment'?</td></tr>\n",
    " <tr><td>15</td><td>data_channel_is_bus</td><td>Is data channel 'Business'?</td></tr>\n",
    " <tr><td>16</td><td>data_channel_is_socmed</td><td>Is data channel 'Social Media'?</td></tr>\n",
    " <tr><td>17</td><td>data_channel_is_tech</td><td>Is data channel 'Tech'?</td></tr>\n",
    " <tr><td>18</td><td>data_channel_is_world</td><td>Is data channel 'World'?</td></tr>\n",
    " <tr><td>19</td><td>kw_min_min</td><td>Worst keyword (min. shares)</td></tr>\n",
    " <tr><td>20</td><td>kw_max_min</td><td>Worst keyword (max. shares)</td></tr>\n",
    " <tr><td>21</td><td>kw_avg_min</td><td>Worst keyword (avg. shares)</td></tr>\n",
    " <tr><td>22</td><td>kw_min_max</td><td>Best keyword (min. shares)</td></tr>\n",
    " <tr><td>23</td><td>kw_max_max</td><td>Best keyword (max. shares)</td></tr>\n",
    " <tr><td>24</td><td>kw_avg_max</td><td>Best keyword (avg. shares)</td></tr>\n",
    " <tr><td>25</td><td>kw_min_avg</td><td>Avg. keyword (min. shares)</td></tr>\n",
    " <tr><td>26</td><td>kw_max_avg</td><td>Avg. keyword (max. shares)</td></tr>\n",
    " <tr><td>27</td><td>kw_avg_avg</td><td>Avg. keyword (avg. shares)</td></tr>\n",
    " <tr><td>28</td><td>self_reference_min_shares</td><td>Min. shares of referenced articles in Mashable</td></tr>\n",
    " <tr><td>29</td><td>self_reference_max_shares</td><td>Max. shares of referenced articles in Mashable</td></tr>\n",
    " <tr><td>30</td><td>self_reference_avg_sharess</td><td>Avg. shares of referenced articles in Mashable</td></tr>\n",
    " <tr><td>31</td><td>weekday_is_monday</td><td>Was the article published on a Monday?</td></tr>\n",
    " <tr><td>32</td><td>weekday_is_tuesday</td><td>Was the article published on a Tuesday?</td></tr>\n",
    " <tr><td>33</td><td>weekday_is_wednesday</td><td>Was the article published on a Wednesday?</td></tr>\n",
    " <tr><td>34</td><td>weekday_is_thursday</td><td>Was the article published on a Thursday?</td></tr>\n",
    " <tr><td>35</td><td>weekday_is_friday</td><td>Was the article published on a Friday?</td></tr>\n",
    " <tr><td>36</td><td>weekday_is_saturday</td><td>Was the article published on a Saturday?</td></tr>\n",
    " <tr><td>37</td><td>weekday_is_sunday</td><td> Was the article published on a Sunday?</td></tr>\n",
    " <tr><td>38</td><td>is_weekend</td><td>Was the article published on the weekend?</td></tr>\n",
    " <tr><td>39</td><td>LDA_00</td><td>Closeness to LDA topic 0</td></tr>\n",
    " <tr><td>40</td><td>LDA_01</td><td>Closeness to LDA topic 1</td></tr>\n",
    " <tr><td>41</td><td>LDA_02</td><td>Closeness to LDA topic 2</td></tr>\n",
    " <tr><td>42</td><td>LDA_03</td><td>Closeness to LDA topic 3</td></tr>\n",
    " <tr><td>43</td><td>LDA_04</td><td>Closeness to LDA topic 4</td></tr>\n",
    " <tr><td>44</td><td>global_subjectivity</td><td>Text subjectivity</td></tr>\n",
    " <tr><td>45</td><td>global_sentiment_polarity</td><td>Text sentiment polarity</td></tr>\n",
    " <tr><td>46</td><td>global_rate_positive_words</td><td>Rate of positive words in the content</td></tr>\n",
    " <tr><td>47</td><td>global_rate_negative_words</td><td> Rate of negative words in the content</td></tr>\n",
    " <tr><td>48</td><td>rate_positive_words</td><td>Rate of positive words among non-neutral tokens</td></tr>\n",
    " <tr><td>49</td><td>rate_negative_words</td><td>Rate of negative words among non-neutral tokens</td></tr>\n",
    " <tr><td>50</td><td>avg_positive_polarity</td><td>Avg. polarity of positive words</td></tr>\n",
    " <tr><td>51</td><td>min_positive_polarity</td><td>Min. polarity of positive words</td></tr>\n",
    " <tr><td>52</td><td>max_positive_polarity</td><td>Max. polarity of positive words</td></tr>\n",
    " <tr><td>53</td><td>avg_negative_polarity</td><td>Avg. polarity of negative words</td></tr>\n",
    " <tr><td>54</td><td>min_negative_polarity</td><td>Min. polarity of negative words</td></tr>\n",
    " <tr><td>55</td><td>max_negative_polarity</td><td>Max. polarity of negative words</td></tr>\n",
    " <tr><td>56</td><td>title_subjectivity</td><td>Title subjectivity</td></tr>\n",
    " <tr><td>57</td><td>title_sentiment_polarity</td><td>Title polarity</td></tr>\n",
    " <tr><td>58</td><td>abs_title_subjectivity</td><td>Absolute subjectivity level</td></tr>\n",
    " <tr><td>59</td><td>abs_title_sentiment_polarity</td><td>Absolute polarity level</td></tr>\n",
    "     <tr><td>60</td><td>shares</td><td>Number of shares (target)</td></tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# 2. Pre-processing (up to 3 of 11.2 points)     \n",
    "     \n",
    "     \n",
    "## 2.1 Clean and Load the Dataset (up to 1 of 11.2 points)\n",
    "Use the following two cells (a code cell and, a markdown cell) to: \n",
    "- create a pandas DataFrame by loading a cleaned version of the \"OnlineNewsPopularity.cvs\" file.  \n",
    "- describe the identified noise and the methodology used to fix the problems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we import all the necessary libreries and function that will be used\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# The next import is necessary to do the pre-processing phase\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "\n",
    "# We import the function SMOTENC to use the SMOTE technique also with categorical features\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "\n",
    "# We import the functions necessary for the hyper parameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# We import the functions that is used to instaciate a particular model\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# We import the functions necessary to show the results of our models\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "# We import the function to do the cross-validation\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viene usato l'attributo \"on_bad_lines='skip'\" perchè sono presenti delle righe con un numero di attributi maggiore di 61."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2013/01/07/amazon-instant-...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/01/07/ap-samsung-spon...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/01/07/apple-40-billio...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2013/01/07/astronaut-notre...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.665635</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2013/01/07/att-u-verse-apps/</td>\n",
       "      <td>731.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>0.415646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.540890</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.220192</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url   timedelta  \\\n",
       "0  http://mashable.com/2013/01/07/amazon-instant-...       731.0   \n",
       "1  http://mashable.com/2013/01/07/ap-samsung-spon...       731.0   \n",
       "2  http://mashable.com/2013/01/07/apple-40-billio...       731.0   \n",
       "3  http://mashable.com/2013/01/07/astronaut-notre...       731.0   \n",
       "4   http://mashable.com/2013/01/07/att-u-verse-apps/       731.0   \n",
       "\n",
       "    n_tokens_title   n_tokens_content   n_unique_tokens   n_non_stop_words  \\\n",
       "0             12.0              219.0          0.663594                1.0   \n",
       "1              9.0              255.0          0.604743                1.0   \n",
       "2              9.0              211.0          0.575130                1.0   \n",
       "3              9.0              531.0          0.503788                1.0   \n",
       "4             13.0             1072.0          0.415646                1.0   \n",
       "\n",
       "    n_non_stop_unique_tokens   num_hrefs   num_self_hrefs  num_imgs  ...  \\\n",
       "0                   0.815385         4.0              2.0       1.0  ...   \n",
       "1                   0.791946         3.0              1.0       1.0  ...   \n",
       "2                   0.663866         3.0              1.0       1.0  ...   \n",
       "3                   0.665635         9.0              0.0       1.0  ...   \n",
       "4                   0.540890        19.0             19.0      20.0  ...   \n",
       "\n",
       "   min_positive_polarity   max_positive_polarity   avg_negative_polarity  \\\n",
       "0               0.100000                     0.7               -0.350000   \n",
       "1               0.033333                     0.7               -0.118750   \n",
       "2               0.100000                     1.0               -0.466667   \n",
       "3               0.136364                     0.8               -0.369697   \n",
       "4               0.033333                     1.0               -0.220192   \n",
       "\n",
       "    min_negative_polarity   max_negative_polarity   title_subjectivity  \\\n",
       "0                  -0.600               -0.200000             0.500000   \n",
       "1                  -0.125               -0.100000             0.000000   \n",
       "2                  -0.800               -0.133333             0.000000   \n",
       "3                  -0.600               -0.166667             0.000000   \n",
       "4                  -0.500               -0.050000             0.454545   \n",
       "\n",
       "    title_sentiment_polarity   abs_title_subjectivity  \\\n",
       "0                  -0.187500                 0.000000   \n",
       "1                   0.000000                 0.500000   \n",
       "2                   0.000000                 0.500000   \n",
       "3                   0.000000                 0.500000   \n",
       "4                   0.136364                 0.045455   \n",
       "\n",
       "    abs_title_sentiment_polarity   shares  \n",
       "0                       0.187500      593  \n",
       "1                       0.000000      711  \n",
       "2                       0.000000     1500  \n",
       "3                       0.000000     1200  \n",
       "4                       0.136364      505  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_news_popularity = pd.read_csv('OnlineNewsPopularity.csv', on_bad_lines='skip', low_memory=False)\n",
    "# This code is used to load the cvs file, after 'OnlineNewsPopularity.csv'\n",
    "\n",
    "online_news_popularity.head()\n",
    "#Line 6 just print the \"head\" (i.e. the first 5 rows) of the pandas DataFrame defined in the above lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All'interno del Data Frame sono presenti delle stringhe \" n.a.\" che rappresentano dei Missing Value quindi occorre sostituirle con l'oggetto NaN di Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35154</th>\n",
       "      <td>http://mashable.com/2014/10/21/australian-teen...</td>\n",
       "      <td>79.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>0.531343</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.670157</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.517857</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36556</th>\n",
       "      <td>http://mashable.com/2014/11/09/nypd-marijuana-...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>736.0</td>\n",
       "      <td>0.497151</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.296296</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37909</th>\n",
       "      <td>http://mashable.com/2014/11/30/apple-aids-red-...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>n.a.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38062</th>\n",
       "      <td>http://mashable.com/2014/12/02/map-data-fashio...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>858.0</td>\n",
       "      <td>0.504706</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>n.a.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.384722</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38178</th>\n",
       "      <td>http://mashable.com/2014/12/03/republicans-who...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>0.528889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.688581</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.245238</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url   timedelta  \\\n",
       "35154  http://mashable.com/2014/10/21/australian-teen...        79.0   \n",
       "36556  http://mashable.com/2014/11/09/nypd-marijuana-...        59.0   \n",
       "37909  http://mashable.com/2014/11/30/apple-aids-red-...        37.0   \n",
       "38062  http://mashable.com/2014/12/02/map-data-fashio...        36.0   \n",
       "38178  http://mashable.com/2014/12/03/republicans-who...        34.0   \n",
       "\n",
       "        n_tokens_title   n_tokens_content   n_unique_tokens  \\\n",
       "35154             12.0              336.0          0.531343   \n",
       "36556             13.0              736.0          0.497151   \n",
       "37909              9.0                0.0          0.000000   \n",
       "38062             14.0              858.0          0.504706   \n",
       "38178             13.0              453.0          0.528889   \n",
       "\n",
       "        n_non_stop_words   n_non_stop_unique_tokens   num_hrefs  \\\n",
       "35154                1.0                   0.670157         5.0   \n",
       "36556                1.0                   0.656250        32.0   \n",
       "37909                0.0                   0.000000         0.0   \n",
       "38062                1.0                   0.682927        21.0   \n",
       "38178                1.0                   0.688581         1.0   \n",
       "\n",
       "        num_self_hrefs  num_imgs  ...  min_positive_polarity  \\\n",
       "35154              4.0       1.0  ...               0.136364   \n",
       "36556              1.0       1.0  ...               0.050000   \n",
       "37909              0.0       0.0  ...               0.000000   \n",
       "38062              8.0      n.a.  ...               0.050000   \n",
       "38178              1.0       1.0  ...               0.050000   \n",
       "\n",
       "        max_positive_polarity   avg_negative_polarity   min_negative_polarity  \\\n",
       "35154                     0.8               -0.150000                   -0.25   \n",
       "36556                     1.0               -0.296296                   -0.80   \n",
       "37909                     0.0                0.000000                    0.00   \n",
       "38062                     0.6               -0.384722                   -1.00   \n",
       "38178                     0.7               -0.245238                   -0.40   \n",
       "\n",
       "        max_negative_polarity   title_subjectivity   title_sentiment_polarity  \\\n",
       "35154               -0.050000             0.517857                   0.392857   \n",
       "36556               -0.033333             0.650000                  -0.500000   \n",
       "37909                0.000000             0.000000                   0.000000   \n",
       "38062               -0.100000             0.544444                   0.350000   \n",
       "38178               -0.150000             0.433333                  -0.166667   \n",
       "\n",
       "        abs_title_subjectivity   abs_title_sentiment_polarity   shares  \n",
       "35154                 0.017857                       0.392857     1100  \n",
       "36556                 0.150000                       0.500000     1800  \n",
       "37909                 0.500000                       0.000000     n.a.  \n",
       "38062                 0.044444                       0.350000      538  \n",
       "38178                 0.066667                       0.166667      510  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_news_popularity[online_news_popularity.eq(\" n.a.\").any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [url,  timedelta,  n_tokens_title,  n_tokens_content,  n_unique_tokens,  n_non_stop_words,  n_non_stop_unique_tokens,  num_hrefs,  num_self_hrefs,  num_imgs,  num_videos,  average_token_length,  num_keywords,  data_channel_is_lifestyle,  data_channel_is_entertainment,  data_channel_is_bus,  data_channel_is_socmed,  data_channel_is_tech,  data_channel_is_world,  kw_min_min,  kw_max_min,  kw_avg_min,  kw_min_max,  kw_max_max,  kw_avg_max,  kw_min_avg,  kw_max_avg,  kw_avg_avg,  self_reference_min_shares,  self_reference_max_shares,  self_reference_avg_sharess,  weekday_is_monday,  weekday_is_tuesday,  weekday_is_wednesday,  weekday_is_thursday,  weekday_is_friday,  weekday_is_saturday,  weekday_is_sunday,  is_weekend,  LDA_00,  LDA_01,  LDA_02,  LDA_03,  LDA_04,  global_subjectivity,  global_sentiment_polarity,  global_rate_positive_words,  global_rate_negative_words,  rate_positive_words,  rate_negative_words,  avg_positive_polarity,  min_positive_polarity,  max_positive_polarity,  avg_negative_polarity,  min_negative_polarity,  max_negative_polarity,  title_subjectivity,  title_sentiment_polarity,  abs_title_subjectivity,  abs_title_sentiment_polarity,  shares]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 61 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_news_popularity = online_news_popularity.replace([' n.a.'], np.nan)\n",
    "online_news_popularity[online_news_popularity.eq(\" n.a.\").any(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo se sono presenti i Missing Value. We will then use Pandas’ data frame attributes, ‘.isna()’ and ‘.isany()’, to detect missing values. These attributes will return Boolean values where ‘True’ indicates that there are missing values in the particular column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url                              False\n",
       " timedelta                        True\n",
       " n_tokens_title                   True\n",
       " n_tokens_content                 True\n",
       " n_unique_tokens                  True\n",
       "                                 ...  \n",
       " title_subjectivity               True\n",
       " title_sentiment_polarity         True\n",
       " abs_title_subjectivity           True\n",
       " abs_title_sentiment_polarity     True\n",
       " shares                           True\n",
       "Length: 61, dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_news_popularity.isna().any()\n",
    "# online_news_popularity.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo quanti Missing Value sono presenti in ciascuna colonna. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url                              0\n",
       " timedelta                       1\n",
       " n_tokens_title                  1\n",
       " n_tokens_content                1\n",
       " n_unique_tokens                 1\n",
       "                                ..\n",
       " title_subjectivity              7\n",
       " title_sentiment_polarity        7\n",
       " abs_title_subjectivity          7\n",
       " abs_title_sentiment_polarity    7\n",
       " shares                          9\n",
       "Length: 61, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_news_popularity.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general when the missing values are <= 10% of the total number of samples, then the samples containing the missing value are discarded, instead, if the missing values are >= 50% of the total number of samples, then the all feater with the missing values is discarded. In this case, the missing values are around 22% of the total number of samples, so we are going to impute those missing values. Metadata.Publishers is a categorical feature and so we can use a simple imputer with strategy=\"most_frequent\" in order to impute the missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Totale dei Missing Value nel Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_news_popularity.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uno dei modi più semplici per rimuovere le righe contenenti Missing Value è usare il \"drop\".\n",
    "Iniziamo droppando tutte le righe contenenti almeno un Missing Value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Shape:  (39647, 61)\n",
      "New Shape:  (39634, 61)\n"
     ]
    }
   ],
   "source": [
    "clean_onp = online_news_popularity.dropna(how=\"any\")\n",
    "print(\"Old Shape: \", online_news_popularity.shape)\n",
    "print(\"New Shape: \", clean_onp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come possiamo notare il numero di righe cancellato non è grande, quindi non perdiamo informazioni strettamente necessarie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_onp.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc = preprocessing.OrdinalEncoder()\n",
    "# onp_reshaped = np.array(onp['url']).reshape(-1, 1)\n",
    "# onp[\"url\"] = enc.fit_transform(onp_reshaped)\n",
    "\n",
    "# print(\"Shape: \", onp.shape)\n",
    "# onp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = MinMaxScaler()\n",
    "#onp = pd.DataFrame(scaler.fit_transform(onp), columns=onp.columns)\n",
    "\n",
    "#print(onp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Dataset Analysis (up to 1 of 11.2 points)\n",
    "In the following code cell (feel free to create new cells), remember to comment your code snippets:\n",
    "\n",
    "1) Print the total number of samples;\n",
    "\n",
    "2) Print a table with the first 15 samples;\n",
    "\n",
    "3) Plot the histogram distribution of \"shares\";\n",
    "\n",
    "4) A bar chart counting the attributes:  data_channel_is_lifestyle, data_channel_is_entertainment, data_channel_is_bus, data_channel_is_socmed, data_channel_is_tech, data_channel_is_world;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Print the total number of samples;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39634, 61)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This first code shows the \"shape\" of the CSV file (i.e. the shape of the samples)\n",
    "clean_onp.shape\n",
    "\n",
    "#This second code just show the lenght of the Pandas DataFrame\n",
    "# len(online_news_popularity.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Print a table with the first 15 samples;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different ways to answer this question. In the following cell, we are going to show the easy way, but there are other methods that we can use, like:\n",
    "\n",
    "1) online_news_popularity.loc[:15] that select the rows where we are interested to \"by label\"; \n",
    "\n",
    "2) online_news_popularity.iloc[:15,a:b] that select the rows where we are interested in \"by position\" and also allow us to select a range of features that we want to show. 'a' and 'b' represent, respectively, the start and the finish column (feature) that we want to show.\n",
    "\n",
    "The difference with the respect to the first method is that in this method we only print the length of the pandas DataFrame and not also the number of features present in the DataSet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2013/01/07/amazon-instant-...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.6000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/01/07/ap-samsung-spon...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>-0.1250</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/01/07/apple-40-billio...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.8000</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2013/01/07/astronaut-notre...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.665635</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>-0.6000</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2013/01/07/att-u-verse-apps/</td>\n",
       "      <td>731.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>0.415646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.540890</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.220192</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://mashable.com/2013/01/07/beewi-smart-toys/</td>\n",
       "      <td>731.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>0.559889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.698198</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.195000</td>\n",
       "      <td>-0.4000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>http://mashable.com/2013/01/07/bodymedia-armba...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>0.418163</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.549834</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.224479</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>http://mashable.com/2013/01/07/canon-poweshot-n/</td>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>989.0</td>\n",
       "      <td>0.433574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.572108</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.242778</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>http://mashable.com/2013/01/07/car-of-the-futu...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.670103</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>-0.1250</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>http://mashable.com/2013/01/07/chuck-hagel-web...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.238095</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>http://mashable.com/2013/01/07/cosmic-events-d...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1248.0</td>\n",
       "      <td>0.490050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.731638</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.415064</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>http://mashable.com/2013/01/07/crayon-creatures/</td>\n",
       "      <td>731.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.262500</td>\n",
       "      <td>-0.4000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>http://mashable.com/2013/01/07/creature-cups/</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.310417</td>\n",
       "      <td>-0.6000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>http://mashable.com/2013/01/07/dad-jokes/</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.841530</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.337889</td>\n",
       "      <td>-0.7000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>http://mashable.com/2013/01/07/downton-abbey-t...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>0.562753</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.138690</td>\n",
       "      <td>-0.1875</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  url   timedelta  \\\n",
       "0   http://mashable.com/2013/01/07/amazon-instant-...       731.0   \n",
       "1   http://mashable.com/2013/01/07/ap-samsung-spon...       731.0   \n",
       "2   http://mashable.com/2013/01/07/apple-40-billio...       731.0   \n",
       "3   http://mashable.com/2013/01/07/astronaut-notre...       731.0   \n",
       "4    http://mashable.com/2013/01/07/att-u-verse-apps/       731.0   \n",
       "5    http://mashable.com/2013/01/07/beewi-smart-toys/       731.0   \n",
       "6   http://mashable.com/2013/01/07/bodymedia-armba...       731.0   \n",
       "7    http://mashable.com/2013/01/07/canon-poweshot-n/       731.0   \n",
       "8   http://mashable.com/2013/01/07/car-of-the-futu...       731.0   \n",
       "9   http://mashable.com/2013/01/07/chuck-hagel-web...       731.0   \n",
       "10  http://mashable.com/2013/01/07/cosmic-events-d...       731.0   \n",
       "11   http://mashable.com/2013/01/07/crayon-creatures/       731.0   \n",
       "12      http://mashable.com/2013/01/07/creature-cups/       731.0   \n",
       "13          http://mashable.com/2013/01/07/dad-jokes/       731.0   \n",
       "14  http://mashable.com/2013/01/07/downton-abbey-t...       731.0   \n",
       "\n",
       "     n_tokens_title   n_tokens_content   n_unique_tokens   n_non_stop_words  \\\n",
       "0              12.0              219.0          0.663594                1.0   \n",
       "1               9.0              255.0          0.604743                1.0   \n",
       "2               9.0              211.0          0.575130                1.0   \n",
       "3               9.0              531.0          0.503788                1.0   \n",
       "4              13.0             1072.0          0.415646                1.0   \n",
       "5              10.0              370.0          0.559889                1.0   \n",
       "6               8.0              960.0          0.418163                1.0   \n",
       "7              12.0              989.0          0.433574                1.0   \n",
       "8              11.0               97.0          0.670103                1.0   \n",
       "9              10.0              231.0          0.636364                1.0   \n",
       "10              9.0             1248.0          0.490050                1.0   \n",
       "11             10.0              187.0          0.666667                1.0   \n",
       "12              9.0              274.0          0.609195                1.0   \n",
       "13              9.0              285.0          0.744186                1.0   \n",
       "14              8.0              259.0          0.562753                1.0   \n",
       "\n",
       "     n_non_stop_unique_tokens   num_hrefs   num_self_hrefs  num_imgs  ...  \\\n",
       "0                    0.815385         4.0              2.0       1.0  ...   \n",
       "1                    0.791946         3.0              1.0       1.0  ...   \n",
       "2                    0.663866         3.0              1.0       1.0  ...   \n",
       "3                    0.665635         9.0              0.0       1.0  ...   \n",
       "4                    0.540890        19.0             19.0      20.0  ...   \n",
       "5                    0.698198         2.0              2.0       0.0  ...   \n",
       "6                    0.549834        21.0             20.0      20.0  ...   \n",
       "7                    0.572108        20.0             20.0      20.0  ...   \n",
       "8                    0.836735         2.0              0.0       0.0  ...   \n",
       "9                    0.797101         4.0              1.0       1.0  ...   \n",
       "10                   0.731638        11.0              0.0       1.0  ...   \n",
       "11                   0.800000         7.0              0.0       1.0  ...   \n",
       "12                   0.707602        18.0              2.0      11.0  ...   \n",
       "13                   0.841530         4.0              2.0       0.0  ...   \n",
       "14                   0.644444        19.0              3.0       9.0  ...   \n",
       "\n",
       "    min_positive_polarity   max_positive_polarity   avg_negative_polarity  \\\n",
       "0                0.100000                     0.7               -0.350000   \n",
       "1                0.033333                     0.7               -0.118750   \n",
       "2                0.100000                     1.0               -0.466667   \n",
       "3                0.136364                     0.8               -0.369697   \n",
       "4                0.033333                     1.0               -0.220192   \n",
       "5                0.136364                     0.6               -0.195000   \n",
       "6                0.100000                     1.0               -0.224479   \n",
       "7                0.100000                     1.0               -0.242778   \n",
       "8                0.400000                     0.8               -0.125000   \n",
       "9                0.100000                     0.5               -0.238095   \n",
       "10               0.100000                     1.0               -0.415064   \n",
       "11               0.200000                     0.7               -0.262500   \n",
       "12               0.200000                     0.7               -0.310417   \n",
       "13               0.160000                     1.0               -0.337889   \n",
       "14               0.136364                     0.5               -0.138690   \n",
       "\n",
       "     min_negative_polarity   max_negative_polarity   title_subjectivity  \\\n",
       "0                  -0.6000               -0.200000             0.500000   \n",
       "1                  -0.1250               -0.100000             0.000000   \n",
       "2                  -0.8000               -0.133333             0.000000   \n",
       "3                  -0.6000               -0.166667             0.000000   \n",
       "4                  -0.5000               -0.050000             0.454545   \n",
       "5                  -0.4000               -0.100000             0.642857   \n",
       "6                  -0.5000               -0.050000             0.000000   \n",
       "7                  -0.5000               -0.050000             1.000000   \n",
       "8                  -0.1250               -0.125000             0.125000   \n",
       "9                  -0.5000               -0.100000             0.000000   \n",
       "10                 -1.0000               -0.100000             0.000000   \n",
       "11                 -0.4000               -0.125000             0.000000   \n",
       "12                 -0.6000               -0.050000             1.000000   \n",
       "13                 -0.7000               -0.100000             1.000000   \n",
       "14                 -0.1875               -0.050000             0.750000   \n",
       "\n",
       "     title_sentiment_polarity   abs_title_subjectivity  \\\n",
       "0                   -0.187500                 0.000000   \n",
       "1                    0.000000                 0.500000   \n",
       "2                    0.000000                 0.500000   \n",
       "3                    0.000000                 0.500000   \n",
       "4                    0.136364                 0.045455   \n",
       "5                    0.214286                 0.142857   \n",
       "6                    0.000000                 0.500000   \n",
       "7                    0.500000                 0.500000   \n",
       "8                    0.000000                 0.375000   \n",
       "9                    0.000000                 0.500000   \n",
       "10                   0.000000                 0.500000   \n",
       "11                   0.000000                 0.500000   \n",
       "12                  -1.000000                 0.500000   \n",
       "13                  -1.000000                 0.500000   \n",
       "14                   0.550000                 0.250000   \n",
       "\n",
       "     abs_title_sentiment_polarity   shares  \n",
       "0                        0.187500      593  \n",
       "1                        0.000000      711  \n",
       "2                        0.000000     1500  \n",
       "3                        0.000000     1200  \n",
       "4                        0.136364      505  \n",
       "5                        0.214286      855  \n",
       "6                        0.000000      556  \n",
       "7                        0.500000      891  \n",
       "8                        0.000000     3600  \n",
       "9                        0.000000      710  \n",
       "10                       0.000000     2200  \n",
       "11                       0.000000     1900  \n",
       "12                       1.000000      823  \n",
       "13                       1.000000    10000  \n",
       "14                       0.550000      761  \n",
       "\n",
       "[15 rows x 61 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is the easy way, just take the samples from the first one to the 15th\n",
    "clean_onp[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Plot the histogram distribution of \"shares\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1100     2307\n",
      " 1200     2017\n",
      " 1300     1739\n",
      " 1400     1592\n",
      " 1500     1323\n",
      "          ... \n",
      " 96100       1\n",
      " 443         1\n",
      " 58100       1\n",
      " 360         1\n",
      " 45000       1\n",
      "Name:  shares, Length: 1454, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(clean_onp[\" shares\"].value_counts()) \n",
    "plt.hist(clean_onp[\" shares\"])\n",
    "plt.title(\"Feature: Shares Original\")\n",
    "plt.show()\n",
    "\n",
    "# quantile_transformer = preprocessing.QuantileTransformer(random_state=0,n_quantiles=112, output_distribution='normal')\n",
    "# onp_reshaped = np.array(onp[' shares']).reshape(-1, 1)\n",
    "# onp_qtrans = quantile_transformer.fit_transform(onp_reshaped)\n",
    "# plt.hist(onp_qtrans)  # arguments are passed to np.histogram\n",
    "# plt.title(\"Feature: Shares\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) A bar chart counting the attributes:  data_channel_is_lifestyle, data_channel_is_entertainment, data_channel_is_bus, data_channel_is_socmed, data_channel_is_tech, data_channel_is_world;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "attributes = [\" data_channel_is_lifestyle\", \" data_channel_is_entertainment\", \" data_channel_is_bus\", \" data_channel_is_socmed\", \" data_channel_is_tech\", \" data_channel_is_world\"]\n",
    "\n",
    "total_zero = []\n",
    "total_one = []\n",
    "#print(online_news_popularity[\" data_channel_is_world\"].value_counts())\n",
    "\n",
    "for attribute in attributes:\n",
    "    \n",
    "    total_zero.append(clean_onp[attribute].value_counts()[0]) # zero\n",
    "    total_one.append(clean_onp[attribute].value_counts()[1])  # one\n",
    "\n",
    "# Declaring the figure or the plot (y, x) or (width, height)\n",
    "plt.figure(figsize=[20, 10])\n",
    "\n",
    "# Using numpy to group different data with bars\n",
    "X = np.arange(len(total_zero))\n",
    "# Passing the parameters to the bar function, this is the main function which creates the bar plot\n",
    "# Using X now to align the bars side by side\n",
    "\n",
    "for attribute in attributes:\n",
    "    plt.bar(X, total_zero, color = 'orange', width = 0.35)\n",
    "    plt.bar(X + 0.35, total_one, color = 'blue', width = 0.35)\n",
    "    \n",
    "# Creating the legend of the bars in the plot\n",
    "plt.legend(['0', '1'])\n",
    "\n",
    "# Overiding the x axis with the country names\n",
    "plt.xticks([i + 0.35 for i in range(len(attributes))], attributes)\n",
    "\n",
    "# Giving the tilte for the plot\n",
    "plt.title(\"A bar chart counting the attributes\")\n",
    "\n",
    "# Namimg the x and y axis\n",
    "plt.xlabel('Attributes')\n",
    "plt.ylabel('Tot')\n",
    "\n",
    "# Saving the plot as a 'png'\n",
    "#plt.savefig('4BarPlot.png')\n",
    "\n",
    "# Displaying the bar plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "your comments for step 2.2 Dataset Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Feature importance analysis  (up to 1 of 11.2 points)\n",
    "\n",
    "Perform feature importance analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "your comments for step 2.4 Feature importance analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 3. Model Selection (up to 8.2 of 11.2  points)\n",
    "In this part of the challenge you are requested to perform all the necessary steps required in order to design a full fledged classification task on the <b>shares</b> feature.\n",
    "\n",
    "You are requested to perform the following steps having in mind the following: \n",
    "\n",
    "1) the dataset must be properly splitted to perform crossvalidation \n",
    "\n",
    "2) when required, features must be properly encoded\n",
    "\n",
    "3) in order to simplify the problem the target feature can be dicretized <b>(number of classes must be >=5)</b> ;\n",
    "\n",
    "4) for model selection you are requested to consider: \n",
    "\n",
    "- Decision Trees\n",
    "\n",
    "- Support Vector Machines;\n",
    "\n",
    "- An ensamble methodology;\n",
    "\n",
    "- MLPNs.\n",
    "\n",
    "5) hyper-parameter tuning <b>must</b> be performed and discussed;\n",
    "\n",
    "6) apply standardizion and normalization when appropriate;\n",
    "\n",
    "7) remember to use an appropriate evaluation setting (cross-fold etc..)\n",
    "\n",
    "8) describe the measures adopted for the evaluation and discuss the results;\n",
    "\n",
    "9) provide a discussion of the model selection, where you describe the differences in terms of performance and explains the root causes;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is now without missing value, we can so now continue the pre-processing phase. We discretize the class to predict, the feature Shares, to simplify the problem. I decided to discretize the class to predict in 10 bins and so Shares can now have value in range from 0 to 5. In the following, we show the code to compute this operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) in order to simplify the problem the target feature can be dicretized (number of classes must be >=5) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0    7536\n",
      "4.0    6956\n",
      "5.0    6659\n",
      "0.0    6599\n",
      "2.0    6063\n",
      "1.0    5821\n",
      "Name:  shares, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_41260/3172564456.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_onp[\" shares\"] = est.fit_transform(clean_onp[[\" shares\"]])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2013/01/07/amazon-instant-...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/01/07/ap-samsung-spon...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/01/07/apple-40-billio...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2013/01/07/astronaut-notre...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.665635</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2013/01/07/att-u-verse-apps/</td>\n",
       "      <td>731.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>0.415646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.540890</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.220192</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url   timedelta  \\\n",
       "0  http://mashable.com/2013/01/07/amazon-instant-...       731.0   \n",
       "1  http://mashable.com/2013/01/07/ap-samsung-spon...       731.0   \n",
       "2  http://mashable.com/2013/01/07/apple-40-billio...       731.0   \n",
       "3  http://mashable.com/2013/01/07/astronaut-notre...       731.0   \n",
       "4   http://mashable.com/2013/01/07/att-u-verse-apps/       731.0   \n",
       "\n",
       "    n_tokens_title   n_tokens_content   n_unique_tokens   n_non_stop_words  \\\n",
       "0             12.0              219.0          0.663594                1.0   \n",
       "1              9.0              255.0          0.604743                1.0   \n",
       "2              9.0              211.0          0.575130                1.0   \n",
       "3              9.0              531.0          0.503788                1.0   \n",
       "4             13.0             1072.0          0.415646                1.0   \n",
       "\n",
       "    n_non_stop_unique_tokens   num_hrefs   num_self_hrefs  num_imgs  ...  \\\n",
       "0                   0.815385         4.0              2.0       1.0  ...   \n",
       "1                   0.791946         3.0              1.0       1.0  ...   \n",
       "2                   0.663866         3.0              1.0       1.0  ...   \n",
       "3                   0.665635         9.0              0.0       1.0  ...   \n",
       "4                   0.540890        19.0             19.0      20.0  ...   \n",
       "\n",
       "   min_positive_polarity   max_positive_polarity   avg_negative_polarity  \\\n",
       "0               0.100000                     0.7               -0.350000   \n",
       "1               0.033333                     0.7               -0.118750   \n",
       "2               0.100000                     1.0               -0.466667   \n",
       "3               0.136364                     0.8               -0.369697   \n",
       "4               0.033333                     1.0               -0.220192   \n",
       "\n",
       "    min_negative_polarity   max_negative_polarity   title_subjectivity  \\\n",
       "0                  -0.600               -0.200000             0.500000   \n",
       "1                  -0.125               -0.100000             0.000000   \n",
       "2                  -0.800               -0.133333             0.000000   \n",
       "3                  -0.600               -0.166667             0.000000   \n",
       "4                  -0.500               -0.050000             0.454545   \n",
       "\n",
       "    title_sentiment_polarity   abs_title_subjectivity  \\\n",
       "0                  -0.187500                 0.000000   \n",
       "1                   0.000000                 0.500000   \n",
       "2                   0.000000                 0.500000   \n",
       "3                   0.000000                 0.500000   \n",
       "4                   0.136364                 0.045455   \n",
       "\n",
       "    abs_title_sentiment_polarity   shares  \n",
       "0                       0.187500      0.0  \n",
       "1                       0.000000      0.0  \n",
       "2                       0.000000      3.0  \n",
       "3                       0.000000      2.0  \n",
       "4                       0.136364      0.0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = preprocessing.KBinsDiscretizer(n_bins=6, encode='ordinal')\n",
    "clean_onp[\" shares\"] = est.fit_transform(clean_onp[[\" shares\"]])\n",
    "\n",
    "print(clean_onp[\" shares\"].value_counts())\n",
    "clean_onp.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, in this case, the value 3 has a major number of samples, instead, the value 1 has a minor number of samples. We are going to call so the samples with a class value equal to 3 the majority class, and all the other samples with different class values as the minority classes (and so we have five minority classes and one majority class). To balance the classes we apply the SMOTE technique. We are going to show now the code to compute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39634, 60) (39634,)\n"
     ]
    }
   ],
   "source": [
    "X = clean_onp.loc[:, clean_onp.columns != ' shares']\n",
    "y = clean_onp[\" shares\"]\n",
    "\n",
    "#We use a copy od the original dataframe and we define as X the dataframe that do not contain the target class\n",
    "clean_onp_upsampled = clean_onp.copy()\n",
    "#X = clean_onp_upsampled.loc[:, clean_onp.columns != ' shares']\n",
    "\n",
    "#We define as y the dataframe that contain only the target class\n",
    "#y = clean_onp_upsampled[' shares']\n",
    "\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minority1 = clean_onp[clean_onp[' shares']==1]\n",
    "\n",
    "df_majority0 = clean_onp[clean_onp[' shares']==0]\n",
    "df_majority2 = clean_onp[clean_onp[' shares']==2]\n",
    "df_majority3 = clean_onp[clean_onp[' shares']==3]\n",
    "df_majority4 = clean_onp[clean_onp[' shares']==4]\n",
    "df_majority5 = clean_onp[clean_onp[' shares']==5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "maj_class0 = resample(df_majority0, \n",
    "                             replace=True,     \n",
    "                             n_samples=1324,    \n",
    "                             random_state=123) \n",
    "maj_class2 = resample(df_majority2, \n",
    "                             replace=True,     \n",
    "                             n_samples=1324,    \n",
    "                             random_state=123) \n",
    "maj_class3 = resample(df_majority3, \n",
    "                             replace=True,     \n",
    "                             n_samples=1324,    \n",
    "                             random_state=123) \n",
    "maj_class4 = resample(df_majority4, \n",
    "                             replace=True,     \n",
    "                             n_samples=1324,    \n",
    "                             random_state=123) \n",
    "maj_class5 = resample(df_majority5, \n",
    "                             replace=True,     \n",
    "                             n_samples=1324,    \n",
    "                             random_state=123) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    5821\n",
       "0.0    1324\n",
       "2.0    1324\n",
       "3.0    1324\n",
       "4.0    1324\n",
       "5.0    1324\n",
       "Name:  shares, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_onp_sampled = pd.concat([df_minority1,maj_class0,maj_class2,maj_class3,maj_class4, maj_class5])\n",
    "clean_onp_sampled[' shares'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histogram of feature 'timedelta' before the scaling\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "Histogram of feature 'timedelta' after the scaling\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#We make a copy of the original pandas DataFrame\n",
    "onp_scaled = clean_onp.copy()\n",
    "\n",
    "quantile_transformer = preprocessing.QuantileTransformer(random_state=0,n_quantiles=112, output_distribution='normal')\n",
    "\n",
    "#The following lines are used to scale only numerical features, in fact we can't scale categorical features\n",
    "#Moreover we do not scale the class to be predicted \" shares\n",
    "for el in onp_scaled.columns:\n",
    "    if (onp_scaled[el].dtype == 'int64' or onp_scaled[el].dtype == 'float64') and el != ' shares':\n",
    "        #We can't pass a 1D array to quantile_transformer.fit_transform() and so we have to reshape with the\n",
    "        #following easy way\n",
    "        reshape = onp_scaled[el].values.reshape(-1,1)\n",
    "        onp_scaled[el] = quantile_transformer.fit_transform(reshape)\n",
    "\n",
    "#We show how was the distribution before the scaling process\n",
    "print(\"Histogram of feature 'timedelta' before the scaling\")\n",
    "plt.hist(clean_onp[\" timedelta\"])\n",
    "plt.title('timedelta - Before scaling')\n",
    "plt.show()\n",
    "\n",
    "print(\"-----------------------------------------------------------\")\n",
    "\n",
    "#We show how is the distribution after the scaling process\n",
    "print(\"Histogram of feature 'timedelta' after the scaling\")\n",
    "plt.hist(onp_scaled[\" timedelta\"])\n",
    "plt.title('timedelta - After scaling')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell we show the code to normalize numerical features byl2 norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First three values of feature 'n_tokens_content' after the scaling but before the normalization\n",
      "0   -0.832006\n",
      "1   -0.628419\n",
      "2   -0.875990\n",
      "3    0.309743\n",
      "4    1.254489\n",
      "Name:  n_tokens_content, dtype: float64\n",
      "------------------------------------------------\n",
      "First three values of feature 'n_tokens_content' after the scaling and after the normalization\n",
      "0   -0.003271\n",
      "1   -0.002470\n",
      "2   -0.003444\n",
      "3    0.001218\n",
      "4    0.004932\n",
      "Name:  n_tokens_content, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# we make a copy of the scaled pandas dataframe\n",
    "onp_norm = onp_scaled.copy()\n",
    "\n",
    "#The following lines are used to normalize only numerical features, in fact we can't normalize categorical features\n",
    "#Moreover we do not normalize the class to be predicted \"Metrics.Review Score\"\n",
    "for el in onp_norm.columns:\n",
    "    if (onp_norm[el].dtype == 'int64' or onp_norm[el].dtype == 'float64') and el != ' shares':\n",
    "        #We can't pass a 1D array to the function normalize() and so we have to reshape with the following easy way\n",
    "        reshape = onp_norm[el].values.reshape(-1,1)\n",
    "        reshape = preprocessing.normalize([onp_norm[el]], norm='l2')\n",
    "        onp_norm[el] = reshape[0] \n",
    "\n",
    "#We show the first three values of a feature before the normalization\n",
    "print(\"First three values of feature 'n_tokens_content' after the scaling but before the normalization\")\n",
    "print(onp_scaled[' n_tokens_content'].head())\n",
    "\n",
    "print(\"------------------------------------------------\")\n",
    "\n",
    "#We show the first three values of a feature after the normalization\n",
    "print(\"First three values of feature 'n_tokens_content' after the scaling and after the normalization\")\n",
    "print(onp_norm[' n_tokens_content'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our preprocessing phase is now terminated, our dataset does not have missing values, the target class is now discretized and the classes are balanced. Finally, our data (except the target class) are normalized and scaled. We are ready so to start the next step: Model Selection.\n",
    "\n",
    "IMPORTANT: the preprocessing phase also includes encoding but for the reason of simplicity I decided to do it after the splitting of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we are going to experiment different models to predict the target class. We are going to use Decision Tree Classifier, Support Vector Machines Classifier (SVM), an Ensamble Method: Random Forest, and Multi Layer Perceptron Networks (MLPNs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We make 2 copy, one of the normalized, scaled and class balanced data and one of the original one in orther\n",
    "#to compare the results after\n",
    "onp_MS = onp_norm.copy()\n",
    "onp_Worst = clean_onp.copy()\n",
    "\n",
    "#We define the class to predict, y, and all the other features, X.\n",
    "y_MS = onp_MS[' shares']\n",
    "X_MS = onp_MS.drop(' shares', axis=1)\n",
    "\n",
    "y_Worst = onp_Worst[' shares']\n",
    "X_Worst = onp_Worst.drop(' shares', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025632</td>\n",
       "      <td>0.003904</td>\n",
       "      <td>-0.003271</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>-0.003378</td>\n",
       "      <td>0.004919</td>\n",
       "      <td>-0.002969</td>\n",
       "      <td>-0.000612</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>-0.000464</td>\n",
       "      <td>-0.002696</td>\n",
       "      <td>-0.000641</td>\n",
       "      <td>-0.004565</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>-0.006119</td>\n",
       "      <td>-0.006519</td>\n",
       "      <td>0.000635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.025632</td>\n",
       "      <td>-0.003237</td>\n",
       "      <td>-0.002470</td>\n",
       "      <td>0.002505</td>\n",
       "      <td>-0.002699</td>\n",
       "      <td>0.004092</td>\n",
       "      <td>-0.004173</td>\n",
       "      <td>-0.001914</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003511</td>\n",
       "      <td>-0.004579</td>\n",
       "      <td>-0.000464</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>0.002834</td>\n",
       "      <td>-0.000398</td>\n",
       "      <td>-0.006918</td>\n",
       "      <td>-0.001164</td>\n",
       "      <td>0.006519</td>\n",
       "      <td>-0.006866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.025632</td>\n",
       "      <td>-0.003237</td>\n",
       "      <td>-0.003444</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>-0.003829</td>\n",
       "      <td>-0.001116</td>\n",
       "      <td>-0.004173</td>\n",
       "      <td>-0.001914</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006117</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>0.007782</td>\n",
       "      <td>-0.005193</td>\n",
       "      <td>-0.001790</td>\n",
       "      <td>-0.002710</td>\n",
       "      <td>-0.006918</td>\n",
       "      <td>-0.001164</td>\n",
       "      <td>0.006519</td>\n",
       "      <td>-0.006866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.025632</td>\n",
       "      <td>-0.003237</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>-0.001353</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>-0.001042</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>-0.012675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001365</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>-0.003131</td>\n",
       "      <td>-0.000641</td>\n",
       "      <td>-0.003523</td>\n",
       "      <td>-0.006918</td>\n",
       "      <td>-0.001164</td>\n",
       "      <td>0.006519</td>\n",
       "      <td>-0.006866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.025632</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.004932</td>\n",
       "      <td>-0.004725</td>\n",
       "      <td>0.005523</td>\n",
       "      <td>-0.005339</td>\n",
       "      <td>0.004020</td>\n",
       "      <td>0.005535</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>-0.004579</td>\n",
       "      <td>0.007782</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.002460</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>-0.001581</td>\n",
       "      <td>0.000456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   url   timedelta   n_tokens_title   n_tokens_content   n_unique_tokens  \\\n",
       "0  0.0    0.025632         0.003904          -0.003271          0.004615   \n",
       "1  1.0    0.025632        -0.003237          -0.002470          0.002505   \n",
       "2  2.0    0.025632        -0.003237          -0.003444          0.001360   \n",
       "3  3.0    0.025632        -0.003237           0.001218         -0.001353   \n",
       "4  4.0    0.025632         0.006154           0.004932         -0.004725   \n",
       "\n",
       "    n_non_stop_words   n_non_stop_unique_tokens   num_hrefs   num_self_hrefs  \\\n",
       "0          -0.003378                   0.004919   -0.002969        -0.000612   \n",
       "1          -0.002699                   0.004092   -0.004173        -0.001914   \n",
       "2          -0.003829                  -0.001116   -0.004173        -0.001914   \n",
       "3           0.001265                  -0.001042    0.000789        -0.012675   \n",
       "4           0.005523                  -0.005339    0.004020         0.005535   \n",
       "\n",
       "   num_imgs  ...  avg_positive_polarity   min_positive_polarity  \\\n",
       "0       1.0  ...               0.001003                0.000957   \n",
       "1       1.0  ...              -0.003511               -0.004579   \n",
       "2       1.0  ...               0.006117                0.000957   \n",
       "3       1.0  ...               0.001365                0.004016   \n",
       "4      20.0  ...               0.002619               -0.004579   \n",
       "\n",
       "    max_positive_polarity   avg_negative_polarity   min_negative_polarity  \\\n",
       "0               -0.000464               -0.002696               -0.000641   \n",
       "1               -0.000464                0.004152                0.002834   \n",
       "2                0.007782               -0.005193               -0.001790   \n",
       "3                0.000034               -0.003131               -0.000641   \n",
       "4                0.007782                0.001045                0.000070   \n",
       "\n",
       "    max_negative_polarity   title_subjectivity   title_sentiment_polarity  \\\n",
       "0               -0.004565             0.000907                  -0.006119   \n",
       "1               -0.000398            -0.006918                  -0.001164   \n",
       "2               -0.002710            -0.006918                  -0.001164   \n",
       "3               -0.003523            -0.006918                  -0.001164   \n",
       "4                0.002460             0.000674                   0.002773   \n",
       "\n",
       "    abs_title_subjectivity   abs_title_sentiment_polarity  \n",
       "0                -0.006519                       0.000635  \n",
       "1                 0.006519                      -0.006866  \n",
       "2                 0.006519                      -0.006866  \n",
       "3                 0.006519                      -0.006866  \n",
       "4                -0.001581                       0.000456  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before I split the dataset into training and test set I encode the categorical features, in particular,\n",
    "# I decided to use the get_dummies function, since it encodes ONLY categorical features and not also the\n",
    "# numerical ones, moreover, I decide to use it since it is faster then the OneHot function seen during the course\n",
    "# Note that it is not necessary to encode the target feature!!!\n",
    "#features = X_MS.columns[:-1]\n",
    "#X_MS_enc = pd.get_dummies(X_MS[features])\n",
    "#X_Worst_enc = pd.get_dummies(X_Worst[features])\n",
    "\n",
    "enc = preprocessing.OrdinalEncoder()\n",
    "onp_reshaped = np.array(X_MS['url']).reshape(-1, 1)\n",
    "X_MS[\"url\"] = enc.fit_transform(onp_reshaped)\n",
    "\n",
    "onp_reshaped = np.array(X_Worst['url']).reshape(-1, 1)\n",
    "X_Worst[\"url\"] = enc.fit_transform(onp_reshaped)\n",
    "\n",
    "X_MS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the function that splits the pandas dataframe, y_train and y_test contain the ground \n",
    "# truth respectively for X_train and X_test\n",
    "X_train_MS, X_test_MS, y_train_MS, y_test_MS = train_test_split(X_MS, y_MS, test_size=0.2, random_state = 112)\n",
    "\n",
    "X_train_Worst, X_test_Worst, y_train_Worst, y_test_Worst = train_test_split(X_Worst, y_Worst,\n",
    "                                                                            test_size=0.2, random_state = 112)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset is now split the two parts, the training set, and the test set, where the training set contains 80% of samples of the dataset normalized, scaled, and with class balanced, and the test set contains the remaining 20%. We are going to learn a model on the training set and then, do the prediction on the test set. We will see the results of the prediction phase in the model evaluation section where we evaluate these results. Moreover, in that section, we will show the difference with the prediction done on data not scaled, normalized, and without balanced class.\n",
    "\n",
    "Data are also now encoded and then we can use algorithms like Decision Tree Classifier, SVM classifier, and Random Forest that can't handle categorical features. Moreover, if the classes to predict are not balanced this can impact the performance evaluation of some learned model (e.g. Decision Tree, SVM, and Random Forest), but we have already balanced our classes and then this problem won't occur. Finally, we are going to use scaled and normalized data, if we do not scale and normalize the data this can impact the performance evaluation of a Multi Layer Perceptron Networks Classifier. Note that even if we use scaled and normalized data in other models where this is not required, the performance evaluation won't be worst. I decided so to do the split on data with balanced classes and with data scaled and normalized.\n",
    "\n",
    "For each selected model we also do hyperparameter tuning to define the best parameter for each model. The grid search was provided by GridSearchCV that exhaustively generates candidates from a grid of parameter values specified with the param_grid parameter and also was used the RandomizedSearchCV function that implements a randomized search over parameters, where each setting is sampled from a distribution over possible parameter values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree is a supervised machine learning algorithm that creates a tree with three important components:\n",
    "- Test node: that is a test on a specific feature;\n",
    "- Leaf node: that represents a decision (classification);\n",
    "- Enge: That can link two test nodes or one test node to a leaf node.\n",
    "A decision tree can be re-written as a set of rules and the \"function\" to minimize is the depth of the tree, but this is an NP-Hard problem and so a Greedy technique is even good. One possibility is to define \"the order\" of testing the different features, based for example on the information gain that is based on the entropy that represents the \"disorder\" of the set (of instances) that we are using.\n",
    "\n",
    "\n",
    "We are going now to show the necessary code to run a Decision Tree Classifier. We also show the code to find the best parameter for this model.\n",
    "\n",
    "As we said in the previous lines classes are already balanced and categorical features are encoded into numerical ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#We define the parameter to tune, in particular we are making tuning on the criterion, on the minimum number\\n#of samples for a split and the minimum number of sampled in a leaf\\nparameter_DTC = {\\n    \\'criterion\\': [\\'gini\\', \\'entropy\\'],\\n    \\'min_samples_split\\': range(1, 10),\\n    \\'min_samples_leaf\\': range(1, 10),\\n    \\'max_depth\\': [int(x) for x in range(10, 100, 10)]}\\n\\n\\n#Now we use the function GridSearchCV in order to find the best parameter from the ones that we want to tune\\nclf_MS = GridSearchCV(tree.DecisionTreeClassifier(), parameter_DTC, n_jobs = -1) \\n#n_jobs = -1 allow the parallelization\\n\\n#Now we stat to learn the model\\nclf_MS.fit(X_train_MS, y_train_MS) \\n    \\n#We now show the best parameter for processed data\\nbest_params_DTC_MS = clf_MS.best_params_\\n\\nprint(\"Best parameters for scaled, normalized and class balanced data:\", best_params_DTC_MS)\\n\\nprint(\"-----------------------------------------------\")\\n\\n#We now show the best parameter for not processed data\\nclf_Worst = GridSearchCV(tree.DecisionTreeClassifier(), parameter_DTC, n_jobs = -1) \\nclf_Worst.fit(X_train_Worst, y_train_Worst)\\nbest_params_DTC_Worst = clf_Worst.best_params_\\n\\nprint(\"Best parameters for original data:\", best_params_DTC_Worst)\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#We define the parameter to tune, in particular we are making tuning on the criterion, on the minimum number\n",
    "#of samples for a split and the minimum number of sampled in a leaf\n",
    "parameter_DTC = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_samples_split': range(1, 10),\n",
    "    'min_samples_leaf': range(1, 10),\n",
    "    'max_depth': [int(x) for x in range(10, 100, 10)]}\n",
    "\n",
    "\n",
    "#Now we use the function GridSearchCV in order to find the best parameter from the ones that we want to tune\n",
    "clf_MS = GridSearchCV(tree.DecisionTreeClassifier(), parameter_DTC, n_jobs = -1) \n",
    "#n_jobs = -1 allow the parallelization\n",
    "\n",
    "#Now we stat to learn the model\n",
    "clf_MS.fit(X_train_MS, y_train_MS) \n",
    "    \n",
    "#We now show the best parameter for processed data\n",
    "best_params_DTC_MS = clf_MS.best_params_\n",
    "\n",
    "print(\"Best parameters for scaled, normalized and class balanced data:\", best_params_DTC_MS)\n",
    "\n",
    "print(\"-----------------------------------------------\")\n",
    "\n",
    "#We now show the best parameter for not processed data\n",
    "clf_Worst = GridSearchCV(tree.DecisionTreeClassifier(), parameter_DTC, n_jobs = -1) \n",
    "clf_Worst.fit(X_train_Worst, y_train_Worst)\n",
    "best_params_DTC_Worst = clf_Worst.best_params_\n",
    "\n",
    "print(\"Best parameters for original data:\", best_params_DTC_Worst)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 5., 4., ..., 5., 1., 4.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_MS = tree.DecisionTreeClassifier()\n",
    "clf_MS.fit(X_train_MS, y_train_MS)\n",
    "#We now show the best parameter for processed data\n",
    "clf_MS.predict(X_test_MS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 5., 4., ..., 4., 4., 1.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We now show the best parameter for not processed data\n",
    "clf_Worst = tree.DecisionTreeClassifier()\n",
    "clf_Worst.fit(X_train_Worst, y_train_Worst)\n",
    "#We now show the best parameter for processed data\n",
    "clf_Worst.predict(X_test_Worst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now answer a previous question \"6) Perform feature importance analysis;\" and we will show the feature performance analysis obtained from the Decision Tree Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 60 artists>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We store our importances in a list\n",
    "importance = clf_MS.feature_importances_\n",
    "\n",
    "# We define the list of number \n",
    "number_list = [number for number in range(len(importance))]\n",
    "\n",
    "# We plot the feature importance obtained\n",
    "plt.bar(number_list, importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX Value:  0.04433816002777156\n",
      "Index:  27\n"
     ]
    }
   ],
   "source": [
    "# Max Value\n",
    "print(\"MAX Value: \", importance[np.argmax(importance)])\n",
    "\n",
    "# Index Max Value\n",
    "print(\"Index: \", np.argmax(importance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write here your comments for step 3 Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# 4. Summary\n",
    "Provide a summary discussion (in English) of your solution <b>(at least 500 words)</b> feel free to include plots figures and tables.\n",
    "\n",
    "<b>This is a mandatory step</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write here <b>your own</b> summary dicussion (in English) use at least 500 words, "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
