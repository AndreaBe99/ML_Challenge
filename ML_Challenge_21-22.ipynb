{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ad031c2",
   "metadata": {
    "id": "43x6IL9QwucL"
   },
   "source": [
    "# Machine Learning 2021/2022 - Challenge \n",
    "\n",
    "<hr>\n",
    "\n",
    "# Identification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59db59b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T09:48:27.723171Z",
     "iopub.status.busy": "2022-01-05T09:48:27.721517Z",
     "iopub.status.idle": "2022-01-05T09:48:27.739236Z",
     "shell.execute_reply": "2022-01-05T09:48:27.738081Z",
     "shell.execute_reply.started": "2022-01-05T09:48:27.722951Z"
    },
    "id": "L7d-PWF7wucN"
   },
   "outputs": [],
   "source": [
    "yourNameSurname='Andrea Bernini' # e.g., yourNameSurname='Mario Rossi'\n",
    "yourMatricolaNumber='2021867' # e.g., yourMatricolaNumber='12345678'\n",
    "yourStudentEMAIL='bernini.2021867@studenti.uniroma1.it' # e.g., yourStudentEMAIL='rossim.12345678@studenti.uniroma1.it'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14aee5c0",
   "metadata": {
    "id": "89W7WgUQwucO"
   },
   "source": [
    "<hr>\n",
    "\n",
    "## 1. Mandatory Rules:\n",
    "- This year the results of the challenges will count 11,2/28 of your final grade (full info about grades <a href='https://twiki.di.uniroma1.it/twiki/view/ApprAuto '>here</a>).\n",
    "- Only one submission is allowed. We will not consider multiple submissions.\n",
    "- Please remember your solution must be <b>\"YOUR SOLUTION\"</b>, hence you are requested to deliver your individual answers/arguments/opinions/critics.\n",
    "- Mail your solution (with your <b>jupyter notebook</b> and the cleaned dataset) only to stefano.faralli@uniroma1.it <b>deadlines are announced on the ML google group and <a href='https://twiki.di.uniroma1.it/twiki/view/ApprAuto'>here</a> (NO EXCEPTIONS)</b> if you miss to deliver your solution you must wait the next (if any) available deadline. \n",
    "- The subject of your email must be: \"[ML-21-22-Challenge_solution] NAME - SURNAME - MATRICOLA\".\n",
    "- Double check the subject of your email and the attachments.\n",
    "- In case you want to compress the attachment, <b>USE ONLY STANDARD ZIP compression</b> (NO RAR,7Z etc..).\n",
    "- <b>Please sumbit The notebook (with SAVED OUTPUTS) and the cleaned dataset!</b>.\n",
    "- Your solution might be considered as the \"copy\" of others solutions, in that specific case the resulting score for all involved students will be 0/8.\n",
    "- Then read carefully all the part of the jupyter notebook and fill all fields.\n",
    "- <b>solutions (and correspondig points) are evaluated mainly on your thoughts/comments/opinions</b>.  \n",
    "- If you have questions <b>Don't write \"personal\" emails</b> to Stefano Faralli, instead <b>use our google group</b>.\n",
    "- A solution having a summary discussion with less than 500 words is evaluated with 0 points.\n",
    "- Comments summary etc.. must be in <b>English</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35242475",
   "metadata": {
    "id": "TKiXBP7CwucP"
   },
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "### Dataset and task Description:\n",
    "<img width='400' src='news-online.jpeg'/>\n",
    "\n",
    "- The challenge is about online news popularity;\n",
    "- The provided dataset consists of one single csv file (\"OnlineNewsPopularity.csv\");\n",
    "- The provided dataset is a modified <b>noisy</b> version of the original dataset described in [1];\n",
    "\n",
    "[1] K. Fernandes, P. Vinagre and P. Cortez. A Proactive Intelligent Decision\n",
    "    Support System for Predicting the Popularity of Online News. Proceedings\n",
    "    of the 17th EPIA 2015 - Portuguese Conference on Artificial Intelligence,\n",
    "    September, Coimbra, Portugal\n",
    "\n",
    "\n",
    "This dataset summarizes a heterogeneous set of features about articles published by Mashable in a period of two years. The goal of the task is to predict the number of shares in social networks (popularity).\n",
    "\n",
    "Number of Instances: <b>39,797</b> \n",
    "\n",
    "Number of Attributes: <b>61</b>\n",
    "\n",
    "Target: <b>shares</b>\n",
    "\n",
    "### Attribute Information:\n",
    "\n",
    "<table>\n",
    " <tr><th> index </th><th>name</th><th>description</th></tr>\n",
    " <tr><td>0</td><td>url</td><td>URL of the article</td></tr>\n",
    " <tr><td>1</td><td>timedelta</td><td>Days between the article publication and the dataset acquisition</td></tr>\n",
    " <tr><td>2</td><td>n_tokens_title</td><td>Number of words in the title</td></tr>\n",
    " <tr><td>3</td><td>n_tokens_content</td><td>Number of words in the content</td></tr>\n",
    " <tr><td>4</td><td>n_unique_tokens</td><td>Rate of unique words in the content</td></tr>\n",
    " <tr><td>5</td><td>n_non_stop_words</td><td>Rate of non-stop words in the content</td></tr>\n",
    " <tr><td>6</td><td>n_non_stop_unique_tokens</td><td>Rate of unique non-stop words in content</td></tr>\n",
    " <tr><td>7</td><td>num_hrefs</td><td>Number of links</td></tr>\n",
    " <tr><td>8</td><td>num_self_hrefs</td><td>Number of links to other articles published by Mashable</td></tr>\n",
    " <tr><td>9</td><td>num_imgs</td><td>Number of images</td></tr>\n",
    " <tr><td>10</td><td>num_videos</td><td>Number of videos</td></tr>\n",
    " <tr><td>11</td><td>average_token_length</td><td>Average length of the words in the content</td></tr>\n",
    " <tr><td>12</td><td>num_keywords</td><td>Number of keywords in the metadata</td></tr>\n",
    " <tr><td>13</td><td>data_channel_is_lifestyle</td><td>Is data channel 'Lifestyle'?</td></tr>\n",
    " <tr><td>14</td><td>data_channel_is_entertainment</td><td>Is data channel 'Entertainment'?</td></tr>\n",
    " <tr><td>15</td><td>data_channel_is_bus</td><td>Is data channel 'Business'?</td></tr>\n",
    " <tr><td>16</td><td>data_channel_is_socmed</td><td>Is data channel 'Social Media'?</td></tr>\n",
    " <tr><td>17</td><td>data_channel_is_tech</td><td>Is data channel 'Tech'?</td></tr>\n",
    " <tr><td>18</td><td>data_channel_is_world</td><td>Is data channel 'World'?</td></tr>\n",
    " <tr><td>19</td><td>kw_min_min</td><td>Worst keyword (min. shares)</td></tr>\n",
    " <tr><td>20</td><td>kw_max_min</td><td>Worst keyword (max. shares)</td></tr>\n",
    " <tr><td>21</td><td>kw_avg_min</td><td>Worst keyword (avg. shares)</td></tr>\n",
    " <tr><td>22</td><td>kw_min_max</td><td>Best keyword (min. shares)</td></tr>\n",
    " <tr><td>23</td><td>kw_max_max</td><td>Best keyword (max. shares)</td></tr>\n",
    " <tr><td>24</td><td>kw_avg_max</td><td>Best keyword (avg. shares)</td></tr>\n",
    " <tr><td>25</td><td>kw_min_avg</td><td>Avg. keyword (min. shares)</td></tr>\n",
    " <tr><td>26</td><td>kw_max_avg</td><td>Avg. keyword (max. shares)</td></tr>\n",
    " <tr><td>27</td><td>kw_avg_avg</td><td>Avg. keyword (avg. shares)</td></tr>\n",
    " <tr><td>28</td><td>self_reference_min_shares</td><td>Min. shares of referenced articles in Mashable</td></tr>\n",
    " <tr><td>29</td><td>self_reference_max_shares</td><td>Max. shares of referenced articles in Mashable</td></tr>\n",
    " <tr><td>30</td><td>self_reference_avg_sharess</td><td>Avg. shares of referenced articles in Mashable</td></tr>\n",
    " <tr><td>31</td><td>weekday_is_monday</td><td>Was the article published on a Monday?</td></tr>\n",
    " <tr><td>32</td><td>weekday_is_tuesday</td><td>Was the article published on a Tuesday?</td></tr>\n",
    " <tr><td>33</td><td>weekday_is_wednesday</td><td>Was the article published on a Wednesday?</td></tr>\n",
    " <tr><td>34</td><td>weekday_is_thursday</td><td>Was the article published on a Thursday?</td></tr>\n",
    " <tr><td>35</td><td>weekday_is_friday</td><td>Was the article published on a Friday?</td></tr>\n",
    " <tr><td>36</td><td>weekday_is_saturday</td><td>Was the article published on a Saturday?</td></tr>\n",
    " <tr><td>37</td><td>weekday_is_sunday</td><td> Was the article published on a Sunday?</td></tr>\n",
    " <tr><td>38</td><td>is_weekend</td><td>Was the article published on the weekend?</td></tr>\n",
    " <tr><td>39</td><td>LDA_00</td><td>Closeness to LDA topic 0</td></tr>\n",
    " <tr><td>40</td><td>LDA_01</td><td>Closeness to LDA topic 1</td></tr>\n",
    " <tr><td>41</td><td>LDA_02</td><td>Closeness to LDA topic 2</td></tr>\n",
    " <tr><td>42</td><td>LDA_03</td><td>Closeness to LDA topic 3</td></tr>\n",
    " <tr><td>43</td><td>LDA_04</td><td>Closeness to LDA topic 4</td></tr>\n",
    " <tr><td>44</td><td>global_subjectivity</td><td>Text subjectivity</td></tr>\n",
    " <tr><td>45</td><td>global_sentiment_polarity</td><td>Text sentiment polarity</td></tr>\n",
    " <tr><td>46</td><td>global_rate_positive_words</td><td>Rate of positive words in the content</td></tr>\n",
    " <tr><td>47</td><td>global_rate_negative_words</td><td> Rate of negative words in the content</td></tr>\n",
    " <tr><td>48</td><td>rate_positive_words</td><td>Rate of positive words among non-neutral tokens</td></tr>\n",
    " <tr><td>49</td><td>rate_negative_words</td><td>Rate of negative words among non-neutral tokens</td></tr>\n",
    " <tr><td>50</td><td>avg_positive_polarity</td><td>Avg. polarity of positive words</td></tr>\n",
    " <tr><td>51</td><td>min_positive_polarity</td><td>Min. polarity of positive words</td></tr>\n",
    " <tr><td>52</td><td>max_positive_polarity</td><td>Max. polarity of positive words</td></tr>\n",
    " <tr><td>53</td><td>avg_negative_polarity</td><td>Avg. polarity of negative words</td></tr>\n",
    " <tr><td>54</td><td>min_negative_polarity</td><td>Min. polarity of negative words</td></tr>\n",
    " <tr><td>55</td><td>max_negative_polarity</td><td>Max. polarity of negative words</td></tr>\n",
    " <tr><td>56</td><td>title_subjectivity</td><td>Title subjectivity</td></tr>\n",
    " <tr><td>57</td><td>title_sentiment_polarity</td><td>Title polarity</td></tr>\n",
    " <tr><td>58</td><td>abs_title_subjectivity</td><td>Absolute subjectivity level</td></tr>\n",
    " <tr><td>59</td><td>abs_title_sentiment_polarity</td><td>Absolute polarity level</td></tr>\n",
    "     <tr><td>60</td><td>shares</td><td>Number of shares (target)</td></tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31da7c5f",
   "metadata": {
    "id": "o4uNdCG1wucT"
   },
   "source": [
    "<hr>\n",
    "\n",
    "# 2. Pre-processing (up to 3 of 11.2 points)     \n",
    "     \n",
    "     \n",
    "## 2.1 Clean and Load the Dataset (up to 1 of 11.2 points)\n",
    "Use the following two cells (a code cell and, a markdown cell) to: \n",
    "- create a pandas DataFrame by loading a cleaned version of the \"OnlineNewsPopularity.cvs\" file.  \n",
    "- describe the identified noise and the methodology used to fix the problems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48972f50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T09:48:27.741539Z",
     "iopub.status.busy": "2022-01-05T09:48:27.741279Z",
     "iopub.status.idle": "2022-01-05T09:48:28.261072Z",
     "shell.execute_reply": "2022-01-05T09:48:28.260256Z",
     "shell.execute_reply.started": "2022-01-05T09:48:27.741509Z"
    },
    "id": "3gUsDDDvwucU"
   },
   "outputs": [],
   "source": [
    "# Basic libreries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pre-processing phase\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Features Importance\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Model\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Hyper-Parameter Tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010095f5",
   "metadata": {
    "id": "eIDJ4A9mwucU"
   },
   "source": [
    "I use this command to show all 61 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d2c6516",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T09:48:28.262722Z",
     "iopub.status.busy": "2022-01-05T09:48:28.262288Z",
     "iopub.status.idle": "2022-01-05T09:48:28.267303Z",
     "shell.execute_reply": "2022-01-05T09:48:28.266363Z",
     "shell.execute_reply.started": "2022-01-05T09:48:28.262691Z"
    },
    "id": "w6QFnmpowucU"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0708c6",
   "metadata": {
    "id": "7FL2lBZ8wucU"
   },
   "source": [
    "As a first approach I inspected the original file `OnlineNewsPopularity.csv` and I found several extra `\\n` characters inside some lines, precisely at `39648`, `39646`, `39592`, `36264` and finally in line `39537` in column `7` there is an unnecessary comma that brings the number of columns to 62."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836c468e",
   "metadata": {
    "id": "dpYxQPoNwucV"
   },
   "source": [
    "As indicated by the delivery I have created a correct and clean copy of the original dataset called `CleanOnlineNewsPopularity.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcf4830",
   "metadata": {
    "id": "cgHFyrPEwucV"
   },
   "source": [
    "Inside the dataset there are strings \" `n.a.`\" which represent Missing Values, however they are not recognized by Pandas, so it is necessary to add the `na_values` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7db1c368",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T09:48:28.269251Z",
     "iopub.status.busy": "2022-01-05T09:48:28.269015Z",
     "iopub.status.idle": "2022-01-05T09:48:28.933776Z",
     "shell.execute_reply": "2022-01-05T09:48:28.932919Z",
     "shell.execute_reply.started": "2022-01-05T09:48:28.269223Z"
    },
    "id": "tCFz0Tn8wucV"
   },
   "outputs": [],
   "source": [
    "# These are different paths based on the platform I used.\n",
    "\n",
    "# Google Colab\n",
    "# path = 'https://raw.githubusercontent.com/AndreaBe99/ML_Challenge/main/CleanOnlineNewsPopularity.csv'\n",
    "\n",
    "# Kaggle\n",
    "# path = \"../input/cleadonp/CleanOnlineNewsPopularity.csv\"\n",
    "\n",
    "# Local\n",
    "path = \"CleanOnlineNewsPopularity.csv\"\n",
    "\n",
    "online_news_popularity = pd.read_csv(path, low_memory=False, na_values = [\" n.a.\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d4a401",
   "metadata": {
    "id": "TQ-fTt0VwucV"
   },
   "source": [
    "In the next three cells there are information on the Missing Value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d800a7c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T09:48:28.935354Z",
     "iopub.status.busy": "2022-01-05T09:48:28.935117Z",
     "iopub.status.idle": "2022-01-05T09:48:28.953738Z",
     "shell.execute_reply": "2022-01-05T09:48:28.953152Z",
     "shell.execute_reply.started": "2022-01-05T09:48:28.935327Z"
    },
    "id": "vLPwYX39wucW",
    "outputId": "3a9101cc-a2ca-4953-a321-da220d0d4922"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of Missing Values\n",
    "online_news_popularity.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f58c5431",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T09:48:28.955279Z",
     "iopub.status.busy": "2022-01-05T09:48:28.955051Z",
     "iopub.status.idle": "2022-01-05T09:48:28.970837Z",
     "shell.execute_reply": "2022-01-05T09:48:28.970021Z",
     "shell.execute_reply.started": "2022-01-05T09:48:28.955250Z"
    },
    "id": "hjgYZ-uwwucW",
    "outputId": "31899452-7205-45b9-e7fe-64e9cd54a62d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url                             False\n",
       "timedelta                       False\n",
       "n_tokens_title                  False\n",
       "n_tokens_content                False\n",
       "n_unique_tokens                 False\n",
       "                                ...  \n",
       "title_subjectivity              False\n",
       "title_sentiment_polarity        False\n",
       "abs_title_subjectivity          False\n",
       "abs_title_sentiment_polarity    False\n",
       "shares                           True\n",
       "Length: 61, dtype: bool"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# True if there are Missing Value in the features, False otherwise\n",
    "online_news_popularity.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0825c84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T09:48:28.972231Z",
     "iopub.status.busy": "2022-01-05T09:48:28.972027Z",
     "iopub.status.idle": "2022-01-05T09:48:28.989630Z",
     "shell.execute_reply": "2022-01-05T09:48:28.989040Z",
     "shell.execute_reply.started": "2022-01-05T09:48:28.972197Z"
    },
    "id": "fbkE7xnswucX",
    "outputId": "a46d3cb4-574b-4fa0-f10d-d9cd2b388533"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url                             0\n",
       "timedelta                       0\n",
       "n_tokens_title                  0\n",
       "n_tokens_content                0\n",
       "n_unique_tokens                 0\n",
       "                               ..\n",
       "title_subjectivity              0\n",
       "title_sentiment_polarity        0\n",
       "abs_title_subjectivity          0\n",
       "abs_title_sentiment_polarity    0\n",
       "shares                          1\n",
       "Length: 61, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of Missing Values for each feature\n",
    "online_news_popularity.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8aae535e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T09:48:28.991021Z",
     "iopub.status.busy": "2022-01-05T09:48:28.990792Z",
     "iopub.status.idle": "2022-01-05T09:48:29.230463Z",
     "shell.execute_reply": "2022-01-05T09:48:29.229594Z",
     "shell.execute_reply.started": "2022-01-05T09:48:28.990955Z"
    },
    "id": "6J089vVZwucX",
    "outputId": "c98974b6-60df-4761-cb92-9b3dd15a50d0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>data_channel_is_lifestyle</th>\n",
       "      <th>data_channel_is_entertainment</th>\n",
       "      <th>data_channel_is_bus</th>\n",
       "      <th>data_channel_is_socmed</th>\n",
       "      <th>data_channel_is_tech</th>\n",
       "      <th>data_channel_is_world</th>\n",
       "      <th>kw_min_min</th>\n",
       "      <th>kw_max_min</th>\n",
       "      <th>kw_avg_min</th>\n",
       "      <th>kw_min_max</th>\n",
       "      <th>kw_max_max</th>\n",
       "      <th>kw_avg_max</th>\n",
       "      <th>kw_min_avg</th>\n",
       "      <th>kw_max_avg</th>\n",
       "      <th>kw_avg_avg</th>\n",
       "      <th>self_reference_min_shares</th>\n",
       "      <th>self_reference_max_shares</th>\n",
       "      <th>self_reference_avg_sharess</th>\n",
       "      <th>weekday_is_monday</th>\n",
       "      <th>weekday_is_tuesday</th>\n",
       "      <th>weekday_is_wednesday</th>\n",
       "      <th>weekday_is_thursday</th>\n",
       "      <th>weekday_is_friday</th>\n",
       "      <th>weekday_is_saturday</th>\n",
       "      <th>weekday_is_sunday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>LDA_00</th>\n",
       "      <th>LDA_01</th>\n",
       "      <th>LDA_02</th>\n",
       "      <th>LDA_03</th>\n",
       "      <th>LDA_04</th>\n",
       "      <th>global_subjectivity</th>\n",
       "      <th>global_sentiment_polarity</th>\n",
       "      <th>global_rate_positive_words</th>\n",
       "      <th>global_rate_negative_words</th>\n",
       "      <th>rate_positive_words</th>\n",
       "      <th>rate_negative_words</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39643.000000</td>\n",
       "      <td>39642.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39643.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39644.000000</td>\n",
       "      <td>39643.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>354.530471</td>\n",
       "      <td>10.398749</td>\n",
       "      <td>546.514731</td>\n",
       "      <td>0.548216</td>\n",
       "      <td>0.996469</td>\n",
       "      <td>0.689175</td>\n",
       "      <td>10.883690</td>\n",
       "      <td>3.293638</td>\n",
       "      <td>4.544257</td>\n",
       "      <td>1.249937</td>\n",
       "      <td>4.548239</td>\n",
       "      <td>7.223767</td>\n",
       "      <td>0.052946</td>\n",
       "      <td>0.178009</td>\n",
       "      <td>0.157855</td>\n",
       "      <td>0.058597</td>\n",
       "      <td>0.185299</td>\n",
       "      <td>0.212567</td>\n",
       "      <td>26.106801</td>\n",
       "      <td>1153.951682</td>\n",
       "      <td>312.366967</td>\n",
       "      <td>13612.354102</td>\n",
       "      <td>752324.066694</td>\n",
       "      <td>259281.938083</td>\n",
       "      <td>1117.146610</td>\n",
       "      <td>5657.211151</td>\n",
       "      <td>3135.858639</td>\n",
       "      <td>3998.755396</td>\n",
       "      <td>10329.212662</td>\n",
       "      <td>6401.697580</td>\n",
       "      <td>0.168020</td>\n",
       "      <td>0.186409</td>\n",
       "      <td>0.187544</td>\n",
       "      <td>0.183306</td>\n",
       "      <td>0.143805</td>\n",
       "      <td>0.061876</td>\n",
       "      <td>0.069041</td>\n",
       "      <td>0.130915</td>\n",
       "      <td>0.184599</td>\n",
       "      <td>0.141256</td>\n",
       "      <td>0.216321</td>\n",
       "      <td>0.223770</td>\n",
       "      <td>0.234029</td>\n",
       "      <td>0.443370</td>\n",
       "      <td>0.119309</td>\n",
       "      <td>0.039625</td>\n",
       "      <td>0.016612</td>\n",
       "      <td>0.682150</td>\n",
       "      <td>0.287934</td>\n",
       "      <td>0.353825</td>\n",
       "      <td>0.095446</td>\n",
       "      <td>0.756728</td>\n",
       "      <td>-0.259524</td>\n",
       "      <td>-0.521944</td>\n",
       "      <td>-0.107500</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.071425</td>\n",
       "      <td>0.341843</td>\n",
       "      <td>0.156064</td>\n",
       "      <td>3395.447822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>214.163767</td>\n",
       "      <td>2.114037</td>\n",
       "      <td>471.107508</td>\n",
       "      <td>3.520708</td>\n",
       "      <td>5.231231</td>\n",
       "      <td>3.264816</td>\n",
       "      <td>11.332017</td>\n",
       "      <td>3.855141</td>\n",
       "      <td>8.309507</td>\n",
       "      <td>4.107949</td>\n",
       "      <td>0.844406</td>\n",
       "      <td>1.909130</td>\n",
       "      <td>0.223929</td>\n",
       "      <td>0.382525</td>\n",
       "      <td>0.364610</td>\n",
       "      <td>0.234871</td>\n",
       "      <td>0.388545</td>\n",
       "      <td>0.409129</td>\n",
       "      <td>69.633215</td>\n",
       "      <td>3857.990877</td>\n",
       "      <td>620.783887</td>\n",
       "      <td>57986.029357</td>\n",
       "      <td>214502.129573</td>\n",
       "      <td>135102.247285</td>\n",
       "      <td>1137.456951</td>\n",
       "      <td>6098.871957</td>\n",
       "      <td>1318.150397</td>\n",
       "      <td>19738.670516</td>\n",
       "      <td>41027.576613</td>\n",
       "      <td>24211.332231</td>\n",
       "      <td>0.373889</td>\n",
       "      <td>0.389441</td>\n",
       "      <td>0.390353</td>\n",
       "      <td>0.386922</td>\n",
       "      <td>0.350896</td>\n",
       "      <td>0.240933</td>\n",
       "      <td>0.253527</td>\n",
       "      <td>0.337312</td>\n",
       "      <td>0.262975</td>\n",
       "      <td>0.219707</td>\n",
       "      <td>0.282145</td>\n",
       "      <td>0.295191</td>\n",
       "      <td>0.289183</td>\n",
       "      <td>0.116685</td>\n",
       "      <td>0.096931</td>\n",
       "      <td>0.017429</td>\n",
       "      <td>0.010828</td>\n",
       "      <td>0.190206</td>\n",
       "      <td>0.156156</td>\n",
       "      <td>0.104542</td>\n",
       "      <td>0.071315</td>\n",
       "      <td>0.247786</td>\n",
       "      <td>0.127726</td>\n",
       "      <td>0.290290</td>\n",
       "      <td>0.095373</td>\n",
       "      <td>0.324247</td>\n",
       "      <td>0.265450</td>\n",
       "      <td>0.188791</td>\n",
       "      <td>0.226294</td>\n",
       "      <td>11627.089598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.393750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>164.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>0.470870</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625739</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.478404</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>445.000000</td>\n",
       "      <td>141.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "      <td>172846.875000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3562.101631</td>\n",
       "      <td>2382.448566</td>\n",
       "      <td>639.000000</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>981.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025051</td>\n",
       "      <td>0.025012</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.028574</td>\n",
       "      <td>0.396167</td>\n",
       "      <td>0.057757</td>\n",
       "      <td>0.028384</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.306244</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-0.328383</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>946.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>339.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>0.539226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.664082</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>660.000000</td>\n",
       "      <td>235.500000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "      <td>244572.222223</td>\n",
       "      <td>1023.635611</td>\n",
       "      <td>4355.688836</td>\n",
       "      <td>2870.074878</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>2800.000000</td>\n",
       "      <td>2200.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033387</td>\n",
       "      <td>0.033345</td>\n",
       "      <td>0.040004</td>\n",
       "      <td>0.040001</td>\n",
       "      <td>0.040727</td>\n",
       "      <td>0.453457</td>\n",
       "      <td>0.119117</td>\n",
       "      <td>0.039023</td>\n",
       "      <td>0.015337</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.358755</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-0.253333</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>542.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>716.000000</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.754630</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.854839</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>357.000000</td>\n",
       "      <td>7900.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "      <td>330980.000000</td>\n",
       "      <td>2056.781032</td>\n",
       "      <td>6019.953968</td>\n",
       "      <td>3600.229564</td>\n",
       "      <td>2600.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>5200.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240958</td>\n",
       "      <td>0.150831</td>\n",
       "      <td>0.334218</td>\n",
       "      <td>0.375763</td>\n",
       "      <td>0.399986</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>0.177832</td>\n",
       "      <td>0.050279</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.411428</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.186905</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>731.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>8474.000000</td>\n",
       "      <td>701.000000</td>\n",
       "      <td>1042.000000</td>\n",
       "      <td>650.000000</td>\n",
       "      <td>304.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>8.041534</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>298400.000000</td>\n",
       "      <td>42827.857143</td>\n",
       "      <td>843300.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "      <td>3613.039819</td>\n",
       "      <td>298400.000000</td>\n",
       "      <td>43567.659946</td>\n",
       "      <td>843300.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.926994</td>\n",
       "      <td>0.925947</td>\n",
       "      <td>0.919999</td>\n",
       "      <td>0.926534</td>\n",
       "      <td>0.927191</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727841</td>\n",
       "      <td>0.155488</td>\n",
       "      <td>0.184932</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          timedelta  n_tokens_title  n_tokens_content  n_unique_tokens  \\\n",
       "count  39644.000000    39644.000000      39644.000000     39644.000000   \n",
       "mean     354.530471       10.398749        546.514731         0.548216   \n",
       "std      214.163767        2.114037        471.107508         3.520708   \n",
       "min        8.000000        2.000000          0.000000         0.000000   \n",
       "25%      164.000000        9.000000        246.000000         0.470870   \n",
       "50%      339.000000       10.000000        409.000000         0.539226   \n",
       "75%      542.000000       12.000000        716.000000         0.608696   \n",
       "max      731.000000       23.000000       8474.000000       701.000000   \n",
       "\n",
       "       n_non_stop_words  n_non_stop_unique_tokens     num_hrefs  \\\n",
       "count      39644.000000              39644.000000  39644.000000   \n",
       "mean           0.996469                  0.689175     10.883690   \n",
       "std            5.231231                  3.264816     11.332017   \n",
       "min            0.000000                  0.000000      0.000000   \n",
       "25%            1.000000                  0.625739      4.000000   \n",
       "50%            1.000000                  0.690476      8.000000   \n",
       "75%            1.000000                  0.754630     14.000000   \n",
       "max         1042.000000                650.000000    304.000000   \n",
       "\n",
       "       num_self_hrefs      num_imgs    num_videos  average_token_length  \\\n",
       "count    39644.000000  39643.000000  39642.000000          39644.000000   \n",
       "mean         3.293638      4.544257      1.249937              4.548239   \n",
       "std          3.855141      8.309507      4.107949              0.844406   \n",
       "min          0.000000      0.000000      0.000000              0.000000   \n",
       "25%          1.000000      1.000000      0.000000              4.478404   \n",
       "50%          3.000000      1.000000      0.000000              4.664082   \n",
       "75%          4.000000      4.000000      1.000000              4.854839   \n",
       "max        116.000000    128.000000     91.000000              8.041534   \n",
       "\n",
       "       num_keywords  data_channel_is_lifestyle  data_channel_is_entertainment  \\\n",
       "count  39644.000000               39644.000000                   39644.000000   \n",
       "mean       7.223767                   0.052946                       0.178009   \n",
       "std        1.909130                   0.223929                       0.382525   \n",
       "min        1.000000                   0.000000                       0.000000   \n",
       "25%        6.000000                   0.000000                       0.000000   \n",
       "50%        7.000000                   0.000000                       0.000000   \n",
       "75%        9.000000                   0.000000                       0.000000   \n",
       "max       10.000000                   1.000000                       1.000000   \n",
       "\n",
       "       data_channel_is_bus  data_channel_is_socmed  data_channel_is_tech  \\\n",
       "count         39644.000000            39644.000000          39644.000000   \n",
       "mean              0.157855                0.058597              0.185299   \n",
       "std               0.364610                0.234871              0.388545   \n",
       "min               0.000000                0.000000              0.000000   \n",
       "25%               0.000000                0.000000              0.000000   \n",
       "50%               0.000000                0.000000              0.000000   \n",
       "75%               0.000000                0.000000              0.000000   \n",
       "max               1.000000                1.000000              1.000000   \n",
       "\n",
       "       data_channel_is_world    kw_min_min     kw_max_min    kw_avg_min  \\\n",
       "count           39644.000000  39644.000000   39644.000000  39644.000000   \n",
       "mean                0.212567     26.106801    1153.951682    312.366967   \n",
       "std                 0.409129     69.633215    3857.990877    620.783887   \n",
       "min                 0.000000     -1.000000       0.000000     -1.000000   \n",
       "25%                 0.000000     -1.000000     445.000000    141.750000   \n",
       "50%                 0.000000     -1.000000     660.000000    235.500000   \n",
       "75%                 0.000000      4.000000    1000.000000    357.000000   \n",
       "max                 1.000000    377.000000  298400.000000  42827.857143   \n",
       "\n",
       "          kw_min_max     kw_max_max     kw_avg_max    kw_min_avg  \\\n",
       "count   39644.000000   39644.000000   39644.000000  39644.000000   \n",
       "mean    13612.354102  752324.066694  259281.938083   1117.146610   \n",
       "std     57986.029357  214502.129573  135102.247285   1137.456951   \n",
       "min         0.000000       0.000000       0.000000     -1.000000   \n",
       "25%         0.000000  843300.000000  172846.875000      0.000000   \n",
       "50%      1400.000000  843300.000000  244572.222223   1023.635611   \n",
       "75%      7900.000000  843300.000000  330980.000000   2056.781032   \n",
       "max    843300.000000  843300.000000  843300.000000   3613.039819   \n",
       "\n",
       "          kw_max_avg    kw_avg_avg  self_reference_min_shares  \\\n",
       "count   39644.000000  39644.000000               39644.000000   \n",
       "mean     5657.211151   3135.858639                3998.755396   \n",
       "std      6098.871957   1318.150397               19738.670516   \n",
       "min         0.000000      0.000000                   0.000000   \n",
       "25%      3562.101631   2382.448566                 639.000000   \n",
       "50%      4355.688836   2870.074878                1200.000000   \n",
       "75%      6019.953968   3600.229564                2600.000000   \n",
       "max    298400.000000  43567.659946              843300.000000   \n",
       "\n",
       "       self_reference_max_shares  self_reference_avg_sharess  \\\n",
       "count               39644.000000                39644.000000   \n",
       "mean                10329.212662                 6401.697580   \n",
       "std                 41027.576613                24211.332231   \n",
       "min                     0.000000                    0.000000   \n",
       "25%                  1100.000000                  981.187500   \n",
       "50%                  2800.000000                 2200.000000   \n",
       "75%                  8000.000000                 5200.000000   \n",
       "max                843300.000000               843300.000000   \n",
       "\n",
       "       weekday_is_monday  weekday_is_tuesday  weekday_is_wednesday  \\\n",
       "count       39644.000000        39644.000000          39644.000000   \n",
       "mean            0.168020            0.186409              0.187544   \n",
       "std             0.373889            0.389441              0.390353   \n",
       "min             0.000000            0.000000              0.000000   \n",
       "25%             0.000000            0.000000              0.000000   \n",
       "50%             0.000000            0.000000              0.000000   \n",
       "75%             0.000000            0.000000              0.000000   \n",
       "max             1.000000            1.000000              1.000000   \n",
       "\n",
       "       weekday_is_thursday  weekday_is_friday  weekday_is_saturday  \\\n",
       "count         39644.000000       39644.000000         39644.000000   \n",
       "mean              0.183306           0.143805             0.061876   \n",
       "std               0.386922           0.350896             0.240933   \n",
       "min               0.000000           0.000000             0.000000   \n",
       "25%               0.000000           0.000000             0.000000   \n",
       "50%               0.000000           0.000000             0.000000   \n",
       "75%               0.000000           0.000000             0.000000   \n",
       "max               1.000000           1.000000             1.000000   \n",
       "\n",
       "       weekday_is_sunday    is_weekend        LDA_00        LDA_01  \\\n",
       "count       39643.000000  39644.000000  39644.000000  39644.000000   \n",
       "mean            0.069041      0.130915      0.184599      0.141256   \n",
       "std             0.253527      0.337312      0.262975      0.219707   \n",
       "min             0.000000      0.000000      0.000000      0.000000   \n",
       "25%             0.000000      0.000000      0.025051      0.025012   \n",
       "50%             0.000000      0.000000      0.033387      0.033345   \n",
       "75%             0.000000      0.000000      0.240958      0.150831   \n",
       "max             1.000000      1.000000      0.926994      0.925947   \n",
       "\n",
       "             LDA_02        LDA_03        LDA_04  global_subjectivity  \\\n",
       "count  39644.000000  39644.000000  39644.000000         39644.000000   \n",
       "mean       0.216321      0.223770      0.234029             0.443370   \n",
       "std        0.282145      0.295191      0.289183             0.116685   \n",
       "min        0.000000      0.000000      0.000000             0.000000   \n",
       "25%        0.028571      0.028571      0.028574             0.396167   \n",
       "50%        0.040004      0.040001      0.040727             0.453457   \n",
       "75%        0.334218      0.375763      0.399986             0.508333   \n",
       "max        0.919999      0.926534      0.927191             1.000000   \n",
       "\n",
       "       global_sentiment_polarity  global_rate_positive_words  \\\n",
       "count               39644.000000                39644.000000   \n",
       "mean                    0.119309                    0.039625   \n",
       "std                     0.096931                    0.017429   \n",
       "min                    -0.393750                    0.000000   \n",
       "25%                     0.057757                    0.028384   \n",
       "50%                     0.119117                    0.039023   \n",
       "75%                     0.177832                    0.050279   \n",
       "max                     0.727841                    0.155488   \n",
       "\n",
       "       global_rate_negative_words  rate_positive_words  rate_negative_words  \\\n",
       "count                39644.000000         39644.000000         39644.000000   \n",
       "mean                     0.016612             0.682150             0.287934   \n",
       "std                      0.010828             0.190206             0.156156   \n",
       "min                      0.000000             0.000000             0.000000   \n",
       "25%                      0.009615             0.600000             0.185185   \n",
       "50%                      0.015337             0.710526             0.280000   \n",
       "75%                      0.021739             0.800000             0.384615   \n",
       "max                      0.184932             1.000000             1.000000   \n",
       "\n",
       "       avg_positive_polarity  min_positive_polarity  max_positive_polarity  \\\n",
       "count           39644.000000           39644.000000           39644.000000   \n",
       "mean                0.353825               0.095446               0.756728   \n",
       "std                 0.104542               0.071315               0.247786   \n",
       "min                 0.000000               0.000000               0.000000   \n",
       "25%                 0.306244               0.050000               0.600000   \n",
       "50%                 0.358755               0.100000               0.800000   \n",
       "75%                 0.411428               0.100000               1.000000   \n",
       "max                 1.000000               1.000000               1.000000   \n",
       "\n",
       "       avg_negative_polarity  min_negative_polarity  max_negative_polarity  \\\n",
       "count           39644.000000           39644.000000           39644.000000   \n",
       "mean               -0.259524              -0.521944              -0.107500   \n",
       "std                 0.127726               0.290290               0.095373   \n",
       "min                -1.000000              -1.000000              -1.000000   \n",
       "25%                -0.328383              -0.700000              -0.125000   \n",
       "50%                -0.253333              -0.500000              -0.100000   \n",
       "75%                -0.186905              -0.300000              -0.050000   \n",
       "max                 0.000000               0.000000               0.000000   \n",
       "\n",
       "       title_subjectivity  title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "count        39644.000000              39644.000000            39644.000000   \n",
       "mean             0.282353                  0.071425                0.341843   \n",
       "std              0.324247                  0.265450                0.188791   \n",
       "min              0.000000                 -1.000000                0.000000   \n",
       "25%              0.000000                  0.000000                0.166667   \n",
       "50%              0.150000                  0.000000                0.500000   \n",
       "75%              0.500000                  0.150000                0.500000   \n",
       "max              1.000000                  1.000000                0.500000   \n",
       "\n",
       "       abs_title_sentiment_polarity         shares  \n",
       "count                  39644.000000   39643.000000  \n",
       "mean                       0.156064    3395.447822  \n",
       "std                        0.226294   11627.089598  \n",
       "min                        0.000000       1.000000  \n",
       "25%                        0.000000     946.000000  \n",
       "50%                        0.000000    1400.000000  \n",
       "75%                        0.250000    2800.000000  \n",
       "max                        1.000000  843300.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_news_popularity.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fc62d5",
   "metadata": {
    "id": "_coy8d-TH2EV"
   },
   "source": [
    "The values of `url` are unique, ie if *n* is the number of samples then there are *n* different values of `url`. For this reason it is better to drop the features instead of applying the encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ceace42d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T09:48:29.232098Z",
     "iopub.status.busy": "2022-01-05T09:48:29.231849Z",
     "iopub.status.idle": "2022-01-05T09:48:29.262215Z",
     "shell.execute_reply": "2022-01-05T09:48:29.261177Z",
     "shell.execute_reply.started": "2022-01-05T09:48:29.232069Z"
    },
    "id": "N9rogJemwucY",
    "outputId": "beb4ab7b-e239-4d89-dad2-567ea30b5f3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_news_popularity[\"url\"].shape[0] - len(online_news_popularity[\"url\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "125f2473",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T09:48:29.265761Z",
     "iopub.status.busy": "2022-01-05T09:48:29.265491Z",
     "iopub.status.idle": "2022-01-05T09:48:29.285852Z",
     "shell.execute_reply": "2022-01-05T09:48:29.285040Z",
     "shell.execute_reply.started": "2022-01-05T09:48:29.265730Z"
    },
    "id": "1qxbaShawucY"
   },
   "outputs": [],
   "source": [
    "onp = online_news_popularity.copy()\n",
    "onp = onp.drop('url', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac12ad1",
   "metadata": {
    "id": "_vDmqaPbwucY"
   },
   "source": [
    "I check the number and therefore the percentage of Missing Value present in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d10bbaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T09:48:29.287248Z",
     "iopub.status.busy": "2022-01-05T09:48:29.286945Z",
     "iopub.status.idle": "2022-01-05T09:48:29.304731Z",
     "shell.execute_reply": "2022-01-05T09:48:29.303939Z",
     "shell.execute_reply.started": "2022-01-05T09:48:29.287205Z"
    },
    "id": "HMsJI-BtwucY",
    "outputId": "6e6a6f24-6af4-4919-8883-09249aa50975"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Missing Value:  5\n",
      "Percentage of Missing Value:  0.012612249016244578 %\n"
     ]
    }
   ],
   "source": [
    "tot_nan = online_news_popularity.isna().sum().sum()\n",
    "print(\"Number of Missing Value: \", tot_nan)\n",
    "print(\"Percentage of Missing Value: \",(tot_nan * 100) / online_news_popularity.shape[0], \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a2d7cf",
   "metadata": {
    "id": "twSwgrLwwucZ"
   },
   "source": [
    "When the number of missing values is less than 10% of the total number of samples (this case: 0,2%), then simply discard those values.\n",
    "On the other hand, if the number of missing values is about 20% of the total number of samples, it is convenient to impute these missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "032460bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T09:48:29.306169Z",
     "iopub.status.busy": "2022-01-05T09:48:29.305924Z",
     "iopub.status.idle": "2022-01-05T09:48:29.328504Z",
     "shell.execute_reply": "2022-01-05T09:48:29.327884Z",
     "shell.execute_reply.started": "2022-01-05T09:48:29.306140Z"
    },
    "id": "ovjz7jwzwucZ",
    "outputId": "2635ccb0-a823-4f69-bdaf-5857dbac1898"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onp = onp.dropna(how=\"any\")\n",
    "\n",
    "onp.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49210d6",
   "metadata": {
    "id": "pGC1hBWMwucZ"
   },
   "source": [
    "Check if there are duplicate lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aed0a451",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T09:48:29.624371Z",
     "iopub.status.busy": "2022-01-05T09:48:29.624123Z",
     "iopub.status.idle": "2022-01-05T09:48:29.729250Z",
     "shell.execute_reply": "2022-01-05T09:48:29.728430Z",
     "shell.execute_reply.started": "2022-01-05T09:48:29.624342Z"
    },
    "id": "jTPXnVDAwuca",
    "outputId": "f69ed28c-109a-4366-fcc3-611531d6569c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Shape:  (39639, 60)\n",
      "New Shape:  (39639, 60)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Old Shape: \", onp.shape)\n",
    "onp_bin = onp_bin.drop_duplicates()\n",
    "print(\"New Shape: \", onp.shape)\n",
    "\n",
    "onp_bin.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e59f46",
   "metadata": {
    "id": "GSCP8yHxwuca"
   },
   "source": [
    "Now that I have cleaned the dataset I can move on to the preprocessing phase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946ebf17",
   "metadata": {
    "id": "S2umdJL3wuca"
   },
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc3f977",
   "metadata": {
    "id": "wv1QyQQowuca"
   },
   "source": [
    "The preprocessing phase is fundamental in Machine Learning, in fact, the data is rarely ready for use, it can contain typos, it can have missing values and also the data may not be normalized. We therefore need to do some preprocessing work to \"clean\" and normalize the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc067ed4",
   "metadata": {
    "id": "72J2s5dfwuca"
   },
   "source": [
    "##### Discretization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884fdc64",
   "metadata": {
    "id": "3dezuK8Ewuca"
   },
   "source": [
    "To simplify the problem I decided to discretize the target \"shares\" in 5 different classes (this is because the accuracy increases with a smaller number of classes as described on the paper), using the KBinsDiscretizer. I decided to use the \"quantile\" approach to make the features more balanced, even later I apply the SMOTE balance for completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96219471",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T09:48:29.731088Z",
     "iopub.status.busy": "2022-01-05T09:48:29.730861Z",
     "iopub.status.idle": "2022-01-05T09:48:29.751336Z",
     "shell.execute_reply": "2022-01-05T09:48:29.750698Z",
     "shell.execute_reply.started": "2022-01-05T09:48:29.731061Z"
    },
    "id": "k4nDK5x2wucb",
    "outputId": "e3853625-de90-47f2-af26-3c249da320ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0    8823\n",
      "4.0    8079\n",
      "3.0    8009\n",
      "0.0    7926\n",
      "1.0    6802\n",
      "Name: shares, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# DISCRETIZATION\n",
    "onp_disc = onp_bin.copy()\n",
    "est = preprocessing.KBinsDiscretizer(n_bins=5, encode='ordinal', strategy=\"quantile\")\n",
    "onp_disc[\"shares\"] = est.fit_transform(onp_disc[[\"shares\"]])\n",
    "\n",
    "print(onp_disc[\"shares\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca495b0f",
   "metadata": {
    "id": "77nLm8rIwucb"
   },
   "source": [
    "##### Classes Balancement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26b81fa",
   "metadata": {
    "id": "VOYiW_Ktwucb"
   },
   "source": [
    "In this case 'Class 2' has a higher number of samples (8823), while the 'Class 1' has a smaller number of samples (6802).\n",
    "\n",
    "Therefore the class values equal to 2 correspond to the majority class, while all the others to the minority classes, thus obtaining a majority class and 4 minority classes.\n",
    "\n",
    "As mentioned above, to balance the classes I apply the SMOTE technique, that creates new instances of the minority class by forming a convex combination of the neighboring instances.\n",
    "This operation is really important because many algorithms suffer if the classes are not balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "638aae01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T09:48:29.752378Z",
     "iopub.status.busy": "2022-01-05T09:48:29.752169Z",
     "iopub.status.idle": "2022-01-05T09:48:33.311242Z",
     "shell.execute_reply": "2022-01-05T09:48:33.310338Z",
     "shell.execute_reply.started": "2022-01-05T09:48:29.752353Z"
    },
    "id": "-YD9duYswucb",
    "outputId": "d918aa50-668d-4cfd-8501-74277d0a9f54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    8823\n",
       "2.0    8823\n",
       "1.0    8823\n",
       "4.0    8823\n",
       "3.0    8823\n",
       "Name: shares, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BALANCEMENT\n",
    "onp_upsampled = onp_disc.copy()\n",
    "\n",
    "X = onp_upsampled.loc[:, onp_upsampled.columns != 'shares']\n",
    "y = onp_upsampled['shares']\n",
    "\n",
    "smote_enc = SMOTE(random_state=0)\n",
    "X_res, y_res = smote_enc.fit_resample(X, y)\n",
    "\n",
    "onp_upsampled = pd.concat([pd.DataFrame(X_res), pd.DataFrame(y_res)], axis=1)\n",
    "onp_upsampled['shares'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e144fa",
   "metadata": {
    "id": "W-UxQz5rKllp"
   },
   "source": [
    "Classes are now balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee1d4fa",
   "metadata": {
    "id": "NSMxwPSvwucb"
   },
   "source": [
    "##### Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad27c25",
   "metadata": {
    "id": "40l9zuvwwucc"
   },
   "source": [
    " Many algorithms in Machine Learning obtain better performance evaluation if data have a normal distribution and data are normalized, for example the SVM and Multi Layer Perceptron Newtworks models, while for other models such as DTC the data does not need to be scaled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0e3f52",
   "metadata": {
    "id": "c1CL7JH_wucc"
   },
   "source": [
    "For the scaling phase there are several options to use, for example Standard scaling or Min/Max Scaling, but in this case I preferred to map the numerical features in a Gaussian distribution using QuantileTransformer() function, with *output_distribution = 'normal'*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4430af5",
   "metadata": {},
   "source": [
    "We will scale all features except the target.\n",
    "The most intuitive approach was to apply the splitting of the dataframe in X and y, before doing the scaling/normalization, but I do it later because initially I had decided to compare the model train with scaled/normalized and non-scaled data. However, as explained also in the final report for time reasons (due to the too long execution of the non-scaled data) I decided not to make this comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71b1a295",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T09:48:33.312823Z",
     "iopub.status.busy": "2022-01-05T09:48:33.312595Z",
     "iopub.status.idle": "2022-01-05T09:48:34.386875Z",
     "shell.execute_reply": "2022-01-05T09:48:34.386060Z",
     "shell.execute_reply.started": "2022-01-05T09:48:33.312796Z"
    },
    "id": "FA61xH5Xwucc",
    "outputId": "d7de34b2-1c95-4dd6-afe7-f955ca8738a1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SCALE\n",
    "onp_scaled = onp_upsampled.copy()\n",
    "\n",
    "quantile_transformer = preprocessing.QuantileTransformer(random_state=0,n_quantiles=112, output_distribution='normal')\n",
    "\n",
    "plt.hist(onp_scaled[\"n_tokens_content\"])\n",
    "plt.title('n_tokens_content - Before scaling')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "for el in onp_scaled.columns:\n",
    "    if el != 'shares':\n",
    "        # We can't pass a 1D array to normalize()\n",
    "        # We apply reshape \n",
    "        reshape = onp_scaled[el].values.reshape(-1,1)\n",
    "        onp_scaled[el] = quantile_transformer.fit_transform(reshape)\n",
    "\n",
    "plt.hist(onp_scaled[\"n_tokens_content\"])\n",
    "plt.title('n_tokens_content - After scaling')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95de0cbb",
   "metadata": {
    "id": "Q40xZkp_wucc"
   },
   "source": [
    "##### Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00347ad1",
   "metadata": {
    "id": "e89VDV7nwucc"
   },
   "source": [
    "The Normalization phase is used to have a unit norm, there are two possible options which are <i> l1 norm </i> or <i> l2 norm </i>, in this case I decided to normalize the features using <i> l2 norm </i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd0ef19a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T09:48:34.388491Z",
     "iopub.status.busy": "2022-01-05T09:48:34.388255Z",
     "iopub.status.idle": "2022-01-05T09:48:34.439899Z",
     "shell.execute_reply": "2022-01-05T09:48:34.439050Z",
     "shell.execute_reply.started": "2022-01-05T09:48:34.388461Z"
    },
    "id": "8BFPW-Ovwucd",
    "outputId": "a25337db-4c9c-42f9-c135-9e63277e043e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Normalization: \n",
      " 0       -0.853480\n",
      "1       -0.650584\n",
      "2       -0.901039\n",
      "3        0.309743\n",
      "4        1.272302\n",
      "           ...   \n",
      "44110    0.363235\n",
      "44111   -0.029651\n",
      "44112   -0.506302\n",
      "44113    0.915635\n",
      "44114   -0.694001\n",
      "Name: n_tokens_content, Length: 44115, dtype: float64\n",
      "After Normalization: \n",
      " 0       -0.003238\n",
      "1       -0.002468\n",
      "2       -0.003418\n",
      "3        0.001175\n",
      "4        0.004826\n",
      "           ...   \n",
      "44110    0.001378\n",
      "44111   -0.000112\n",
      "44112   -0.001921\n",
      "44113    0.003473\n",
      "44114   -0.002633\n",
      "Name: n_tokens_content, Length: 44115, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# NORMALIZE\n",
    "onp_norm = onp_scaled.copy()\n",
    "\n",
    "print(\"Before Normalization: \\n\", onp_norm['n_tokens_content'])\n",
    "\n",
    "for el in onp_norm.columns:\n",
    "    if el != 'shares':\n",
    "        # We can't pass a 1D array to normalize()\n",
    "        # We apply reshape \n",
    "        reshape = onp_norm[el].values.reshape(-1,1)\n",
    "        onp_norm[el] = preprocessing.normalize([onp_norm[el]], norm='l2')[0]\n",
    "\n",
    "print(\"After Normalization: \\n\", onp_norm['n_tokens_content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221b5f99",
   "metadata": {
    "id": "SnZawO3awucd"
   },
   "source": [
    "##### Traininig and Test data splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b1365d",
   "metadata": {
    "id": "1fYRKZGkwucd"
   },
   "source": [
    "After scaling and normalizing the dataset, I split it into two parts, the training set and the test set, where the training set contains 70% of the normalized, scaled, and class-balanced dataset samples and the test set contains the remaining 30%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e6cceba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T09:48:34.441902Z",
     "iopub.status.busy": "2022-01-05T09:48:34.441428Z",
     "iopub.status.idle": "2022-01-05T09:48:34.486337Z",
     "shell.execute_reply": "2022-01-05T09:48:34.485577Z",
     "shell.execute_reply.started": "2022-01-05T09:48:34.441861Z"
    },
    "id": "cm9n8tqAwucd"
   },
   "outputs": [],
   "source": [
    "# SPLIT\n",
    "onp_better = onp_norm.copy()\n",
    "y = onp_better['shares']\n",
    "X = onp_better.drop('shares', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 112)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dabc64c",
   "metadata": {
    "id": "qTdH2ooXwucd"
   },
   "source": [
    "## 2.2 Dataset Analysis (up to 1 of 11.2 points)\n",
    "In the following code cell (feel free to create new cells), remember to comment your code snippets:\n",
    "\n",
    "1) Print the total number of samples;\n",
    "\n",
    "2) Print a table with the first 15 samples;\n",
    "\n",
    "3) Plot the histogram distribution of \"shares\";\n",
    "\n",
    "4) A bar chart counting the attributes:  data_channel_is_lifestyle, data_channel_is_entertainment, data_channel_is_bus, data_channel_is_socmed, data_channel_is_tech, data_channel_is_world;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4eaceb09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T09:48:34.488335Z",
     "iopub.status.busy": "2022-01-05T09:48:34.487829Z",
     "iopub.status.idle": "2022-01-05T09:48:34.494725Z",
     "shell.execute_reply": "2022-01-05T09:48:34.493811Z",
     "shell.execute_reply.started": "2022-01-05T09:48:34.488291Z"
    },
    "id": "fo-yP2nJwuce",
    "outputId": "9810d103-0a8d-4860-c8ec-b84ba443528c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (39644, 61)\n",
      "Total Samples:  39644\n"
     ]
    }
   ],
   "source": [
    "# 1) Print the total number of samples;\n",
    "print(\"Shape: \", online_news_popularity.shape)\n",
    "print(\"Total Samples: \", len(online_news_popularity.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4a3609c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T09:48:34.496573Z",
     "iopub.status.busy": "2022-01-05T09:48:34.495859Z",
     "iopub.status.idle": "2022-01-05T09:48:34.618374Z",
     "shell.execute_reply": "2022-01-05T09:48:34.617537Z",
     "shell.execute_reply.started": "2022-01-05T09:48:34.496542Z"
    },
    "id": "x6mZ82f0wuce",
    "outputId": "f0d774c7-abde-4996-f647-322425b0f0ff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>data_channel_is_lifestyle</th>\n",
       "      <th>data_channel_is_entertainment</th>\n",
       "      <th>data_channel_is_bus</th>\n",
       "      <th>data_channel_is_socmed</th>\n",
       "      <th>data_channel_is_tech</th>\n",
       "      <th>data_channel_is_world</th>\n",
       "      <th>kw_min_min</th>\n",
       "      <th>kw_max_min</th>\n",
       "      <th>kw_avg_min</th>\n",
       "      <th>kw_min_max</th>\n",
       "      <th>kw_max_max</th>\n",
       "      <th>kw_avg_max</th>\n",
       "      <th>kw_min_avg</th>\n",
       "      <th>kw_max_avg</th>\n",
       "      <th>kw_avg_avg</th>\n",
       "      <th>self_reference_min_shares</th>\n",
       "      <th>self_reference_max_shares</th>\n",
       "      <th>self_reference_avg_sharess</th>\n",
       "      <th>weekday_is_monday</th>\n",
       "      <th>weekday_is_tuesday</th>\n",
       "      <th>weekday_is_wednesday</th>\n",
       "      <th>weekday_is_thursday</th>\n",
       "      <th>weekday_is_friday</th>\n",
       "      <th>weekday_is_saturday</th>\n",
       "      <th>weekday_is_sunday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>LDA_00</th>\n",
       "      <th>LDA_01</th>\n",
       "      <th>LDA_02</th>\n",
       "      <th>LDA_03</th>\n",
       "      <th>LDA_04</th>\n",
       "      <th>global_subjectivity</th>\n",
       "      <th>global_sentiment_polarity</th>\n",
       "      <th>global_rate_positive_words</th>\n",
       "      <th>global_rate_negative_words</th>\n",
       "      <th>rate_positive_words</th>\n",
       "      <th>rate_negative_words</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2013/01/07/amazon-instant-...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.680365</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>496.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500331</td>\n",
       "      <td>0.378279</td>\n",
       "      <td>0.040005</td>\n",
       "      <td>0.041263</td>\n",
       "      <td>0.040123</td>\n",
       "      <td>0.521617</td>\n",
       "      <td>0.092562</td>\n",
       "      <td>0.045662</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.378636</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.6000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>593.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/01/07/ap-samsung-spon...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.913725</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.799756</td>\n",
       "      <td>0.050047</td>\n",
       "      <td>0.050096</td>\n",
       "      <td>0.050101</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.341246</td>\n",
       "      <td>0.148948</td>\n",
       "      <td>0.043137</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.286915</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>-0.1250</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>711.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/01/07/apple-40-billio...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.393365</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.217792</td>\n",
       "      <td>0.033334</td>\n",
       "      <td>0.033351</td>\n",
       "      <td>0.033334</td>\n",
       "      <td>0.682188</td>\n",
       "      <td>0.702222</td>\n",
       "      <td>0.323333</td>\n",
       "      <td>0.056872</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.495833</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.8000</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2013/01/07/astronaut-notre...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.665635</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.404896</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028573</td>\n",
       "      <td>0.419300</td>\n",
       "      <td>0.494651</td>\n",
       "      <td>0.028905</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.429850</td>\n",
       "      <td>0.100705</td>\n",
       "      <td>0.041431</td>\n",
       "      <td>0.020716</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>-0.6000</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2013/01/07/att-u-verse-apps/</td>\n",
       "      <td>731.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>0.415646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.540890</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.682836</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>3151.157895</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028633</td>\n",
       "      <td>0.028794</td>\n",
       "      <td>0.028575</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.885427</td>\n",
       "      <td>0.513502</td>\n",
       "      <td>0.281003</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.012127</td>\n",
       "      <td>0.860215</td>\n",
       "      <td>0.139785</td>\n",
       "      <td>0.411127</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.220192</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>505.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://mashable.com/2013/01/07/beewi-smart-toys/</td>\n",
       "      <td>731.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>0.559889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.698198</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.359459</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>8500.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022245</td>\n",
       "      <td>0.306718</td>\n",
       "      <td>0.022231</td>\n",
       "      <td>0.022224</td>\n",
       "      <td>0.626582</td>\n",
       "      <td>0.437409</td>\n",
       "      <td>0.071184</td>\n",
       "      <td>0.029730</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.350610</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.195000</td>\n",
       "      <td>-0.4000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>855.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>http://mashable.com/2013/01/07/bodymedia-armba...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>0.418163</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.549834</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.654167</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>3151.157895</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020082</td>\n",
       "      <td>0.114705</td>\n",
       "      <td>0.020024</td>\n",
       "      <td>0.020015</td>\n",
       "      <td>0.825173</td>\n",
       "      <td>0.514480</td>\n",
       "      <td>0.268303</td>\n",
       "      <td>0.080208</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.827957</td>\n",
       "      <td>0.172043</td>\n",
       "      <td>0.402039</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.224479</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>556.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>http://mashable.com/2013/01/07/canon-poweshot-n/</td>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>989.0</td>\n",
       "      <td>0.433574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.572108</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.617796</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>3151.157895</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022224</td>\n",
       "      <td>0.150733</td>\n",
       "      <td>0.243435</td>\n",
       "      <td>0.022224</td>\n",
       "      <td>0.561384</td>\n",
       "      <td>0.543474</td>\n",
       "      <td>0.298613</td>\n",
       "      <td>0.083923</td>\n",
       "      <td>0.015167</td>\n",
       "      <td>0.846939</td>\n",
       "      <td>0.153061</td>\n",
       "      <td>0.427720</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.242778</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>891.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>http://mashable.com/2013/01/07/car-of-the-futu...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.670103</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.855670</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458250</td>\n",
       "      <td>0.028979</td>\n",
       "      <td>0.028662</td>\n",
       "      <td>0.029696</td>\n",
       "      <td>0.454412</td>\n",
       "      <td>0.538889</td>\n",
       "      <td>0.161111</td>\n",
       "      <td>0.030928</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>-0.1250</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>http://mashable.com/2013/01/07/chuck-hagel-web...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.090909</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.839997</td>\n",
       "      <td>0.040001</td>\n",
       "      <td>0.040002</td>\n",
       "      <td>0.313889</td>\n",
       "      <td>0.051852</td>\n",
       "      <td>0.038961</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.298413</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.238095</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>710.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>http://mashable.com/2013/01/07/cosmic-events-d...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1248.0</td>\n",
       "      <td>0.490050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.731638</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.617788</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025004</td>\n",
       "      <td>0.287301</td>\n",
       "      <td>0.400829</td>\n",
       "      <td>0.261864</td>\n",
       "      <td>0.025002</td>\n",
       "      <td>0.482060</td>\n",
       "      <td>0.102350</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.404480</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.415064</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>http://mashable.com/2013/01/07/crayon-creatures/</td>\n",
       "      <td>731.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.657754</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028628</td>\n",
       "      <td>0.028573</td>\n",
       "      <td>0.028596</td>\n",
       "      <td>0.028715</td>\n",
       "      <td>0.885488</td>\n",
       "      <td>0.477165</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.026738</td>\n",
       "      <td>0.010695</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.435000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.262500</td>\n",
       "      <td>-0.4000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>http://mashable.com/2013/01/07/creature-cups/</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.233577</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10700.0</td>\n",
       "      <td>16200.0</td>\n",
       "      <td>13450.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150493</td>\n",
       "      <td>0.025934</td>\n",
       "      <td>0.025188</td>\n",
       "      <td>0.304298</td>\n",
       "      <td>0.494088</td>\n",
       "      <td>0.534950</td>\n",
       "      <td>0.100728</td>\n",
       "      <td>0.051095</td>\n",
       "      <td>0.029197</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.375510</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.310417</td>\n",
       "      <td>-0.6000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>823.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>http://mashable.com/2013/01/07/dad-jokes/</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.841530</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.343860</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>770.0</td>\n",
       "      <td>22800.0</td>\n",
       "      <td>11785.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033386</td>\n",
       "      <td>0.033427</td>\n",
       "      <td>0.033352</td>\n",
       "      <td>0.866499</td>\n",
       "      <td>0.033337</td>\n",
       "      <td>0.509744</td>\n",
       "      <td>-0.053085</td>\n",
       "      <td>0.028070</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.457500</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.337889</td>\n",
       "      <td>-0.7000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>http://mashable.com/2013/01/07/downton-abbey-t...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>0.562753</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.023166</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>4800.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028780</td>\n",
       "      <td>0.028814</td>\n",
       "      <td>0.028574</td>\n",
       "      <td>0.885144</td>\n",
       "      <td>0.028687</td>\n",
       "      <td>0.295175</td>\n",
       "      <td>0.057299</td>\n",
       "      <td>0.015444</td>\n",
       "      <td>0.011583</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.249091</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.138690</td>\n",
       "      <td>-0.1875</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>761.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  url  timedelta  \\\n",
       "0   http://mashable.com/2013/01/07/amazon-instant-...      731.0   \n",
       "1   http://mashable.com/2013/01/07/ap-samsung-spon...      731.0   \n",
       "2   http://mashable.com/2013/01/07/apple-40-billio...      731.0   \n",
       "3   http://mashable.com/2013/01/07/astronaut-notre...      731.0   \n",
       "4    http://mashable.com/2013/01/07/att-u-verse-apps/      731.0   \n",
       "5    http://mashable.com/2013/01/07/beewi-smart-toys/      731.0   \n",
       "6   http://mashable.com/2013/01/07/bodymedia-armba...      731.0   \n",
       "7    http://mashable.com/2013/01/07/canon-poweshot-n/      731.0   \n",
       "8   http://mashable.com/2013/01/07/car-of-the-futu...      731.0   \n",
       "9   http://mashable.com/2013/01/07/chuck-hagel-web...      731.0   \n",
       "10  http://mashable.com/2013/01/07/cosmic-events-d...      731.0   \n",
       "11   http://mashable.com/2013/01/07/crayon-creatures/      731.0   \n",
       "12      http://mashable.com/2013/01/07/creature-cups/      731.0   \n",
       "13          http://mashable.com/2013/01/07/dad-jokes/      731.0   \n",
       "14  http://mashable.com/2013/01/07/downton-abbey-t...      731.0   \n",
       "\n",
       "    n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
       "0             12.0             219.0         0.663594               1.0   \n",
       "1              9.0             255.0         0.604743               1.0   \n",
       "2              9.0             211.0         0.575130               1.0   \n",
       "3              9.0             531.0         0.503788               1.0   \n",
       "4             13.0            1072.0         0.415646               1.0   \n",
       "5             10.0             370.0         0.559889               1.0   \n",
       "6              8.0             960.0         0.418163               1.0   \n",
       "7             12.0             989.0         0.433574               1.0   \n",
       "8             11.0              97.0         0.670103               1.0   \n",
       "9             10.0             231.0         0.636364               1.0   \n",
       "10             9.0            1248.0         0.490050               1.0   \n",
       "11            10.0             187.0         0.666667               1.0   \n",
       "12             9.0             274.0         0.609195               1.0   \n",
       "13             9.0             285.0         0.744186               1.0   \n",
       "14             8.0             259.0         0.562753               1.0   \n",
       "\n",
       "    n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs  num_videos  \\\n",
       "0                   0.815385        4.0             2.0       1.0         0.0   \n",
       "1                   0.791946        3.0             1.0       1.0         0.0   \n",
       "2                   0.663866        3.0             1.0       1.0         0.0   \n",
       "3                   0.665635        9.0             0.0       1.0         0.0   \n",
       "4                   0.540890       19.0            19.0      20.0         0.0   \n",
       "5                   0.698198        2.0             2.0       0.0         0.0   \n",
       "6                   0.549834       21.0            20.0      20.0         0.0   \n",
       "7                   0.572108       20.0            20.0      20.0         0.0   \n",
       "8                   0.836735        2.0             0.0       0.0         0.0   \n",
       "9                   0.797101        4.0             1.0       1.0         1.0   \n",
       "10                  0.731638       11.0             0.0       1.0         0.0   \n",
       "11                  0.800000        7.0             0.0       1.0         0.0   \n",
       "12                  0.707602       18.0             2.0      11.0         0.0   \n",
       "13                  0.841530        4.0             2.0       0.0        21.0   \n",
       "14                  0.644444       19.0             3.0       9.0         0.0   \n",
       "\n",
       "    average_token_length  num_keywords  data_channel_is_lifestyle  \\\n",
       "0               4.680365           5.0                        0.0   \n",
       "1               4.913725           4.0                        0.0   \n",
       "2               4.393365           6.0                        0.0   \n",
       "3               4.404896           7.0                        0.0   \n",
       "4               4.682836           7.0                        0.0   \n",
       "5               4.359459           9.0                        0.0   \n",
       "6               4.654167          10.0                        1.0   \n",
       "7               4.617796           9.0                        0.0   \n",
       "8               4.855670           7.0                        0.0   \n",
       "9               5.090909           5.0                        0.0   \n",
       "10              4.617788           8.0                        0.0   \n",
       "11              4.657754           7.0                        1.0   \n",
       "12              4.233577           8.0                        0.0   \n",
       "13              4.343860           6.0                        0.0   \n",
       "14              5.023166           7.0                        0.0   \n",
       "\n",
       "    data_channel_is_entertainment  data_channel_is_bus  \\\n",
       "0                             1.0                  0.0   \n",
       "1                             0.0                  1.0   \n",
       "2                             0.0                  1.0   \n",
       "3                             1.0                  0.0   \n",
       "4                             0.0                  0.0   \n",
       "5                             0.0                  0.0   \n",
       "6                             0.0                  0.0   \n",
       "7                             0.0                  0.0   \n",
       "8                             0.0                  0.0   \n",
       "9                             0.0                  0.0   \n",
       "10                            0.0                  0.0   \n",
       "11                            0.0                  0.0   \n",
       "12                            0.0                  0.0   \n",
       "13                            0.0                  0.0   \n",
       "14                            0.0                  0.0   \n",
       "\n",
       "    data_channel_is_socmed  data_channel_is_tech  data_channel_is_world  \\\n",
       "0                      0.0                   0.0                    0.0   \n",
       "1                      0.0                   0.0                    0.0   \n",
       "2                      0.0                   0.0                    0.0   \n",
       "3                      0.0                   0.0                    0.0   \n",
       "4                      0.0                   1.0                    0.0   \n",
       "5                      0.0                   1.0                    0.0   \n",
       "6                      0.0                   0.0                    0.0   \n",
       "7                      0.0                   1.0                    0.0   \n",
       "8                      0.0                   1.0                    0.0   \n",
       "9                      0.0                   0.0                    1.0   \n",
       "10                     0.0                   0.0                    1.0   \n",
       "11                     0.0                   0.0                    0.0   \n",
       "12                     0.0                   0.0                    0.0   \n",
       "13                     0.0                   0.0                    0.0   \n",
       "14                     0.0                   0.0                    0.0   \n",
       "\n",
       "    kw_min_min  kw_max_min  kw_avg_min  kw_min_max  kw_max_max  kw_avg_max  \\\n",
       "0          0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "1          0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "2          0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "3          0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "4          0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "5          0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "6          0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "7          0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "8          0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "9          0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "10         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "11         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "12         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "13         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "14         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "    kw_min_avg  kw_max_avg  kw_avg_avg  self_reference_min_shares  \\\n",
       "0          0.0         0.0         0.0                      496.0   \n",
       "1          0.0         0.0         0.0                        0.0   \n",
       "2          0.0         0.0         0.0                      918.0   \n",
       "3          0.0         0.0         0.0                        0.0   \n",
       "4          0.0         0.0         0.0                      545.0   \n",
       "5          0.0         0.0         0.0                     8500.0   \n",
       "6          0.0         0.0         0.0                      545.0   \n",
       "7          0.0         0.0         0.0                      545.0   \n",
       "8          0.0         0.0         0.0                        0.0   \n",
       "9          0.0         0.0         0.0                        0.0   \n",
       "10         0.0         0.0         0.0                        0.0   \n",
       "11         0.0         0.0         0.0                        0.0   \n",
       "12         0.0         0.0         0.0                    10700.0   \n",
       "13         0.0         0.0         0.0                      770.0   \n",
       "14         0.0         0.0         0.0                     4800.0   \n",
       "\n",
       "    self_reference_max_shares  self_reference_avg_sharess  weekday_is_monday  \\\n",
       "0                       496.0                  496.000000                1.0   \n",
       "1                         0.0                    0.000000                1.0   \n",
       "2                       918.0                  918.000000                1.0   \n",
       "3                         0.0                    0.000000                1.0   \n",
       "4                     16000.0                 3151.157895                1.0   \n",
       "5                      8500.0                 8500.000000                1.0   \n",
       "6                     16000.0                 3151.157895                1.0   \n",
       "7                     16000.0                 3151.157895                1.0   \n",
       "8                         0.0                    0.000000                1.0   \n",
       "9                         0.0                    0.000000                1.0   \n",
       "10                        0.0                    0.000000                1.0   \n",
       "11                        0.0                    0.000000                1.0   \n",
       "12                    16200.0                13450.000000                1.0   \n",
       "13                    22800.0                11785.000000                1.0   \n",
       "14                     4800.0                 4800.000000                1.0   \n",
       "\n",
       "    weekday_is_tuesday  weekday_is_wednesday  weekday_is_thursday  \\\n",
       "0                  0.0                   0.0                  0.0   \n",
       "1                  0.0                   0.0                  0.0   \n",
       "2                  0.0                   0.0                  0.0   \n",
       "3                  0.0                   0.0                  0.0   \n",
       "4                  0.0                   0.0                  0.0   \n",
       "5                  0.0                   0.0                  0.0   \n",
       "6                  0.0                   0.0                  0.0   \n",
       "7                  0.0                   0.0                  0.0   \n",
       "8                  0.0                   0.0                  0.0   \n",
       "9                  0.0                   0.0                  0.0   \n",
       "10                 0.0                   0.0                  0.0   \n",
       "11                 0.0                   0.0                  0.0   \n",
       "12                 0.0                   0.0                  0.0   \n",
       "13                 0.0                   0.0                  0.0   \n",
       "14                 0.0                   0.0                  0.0   \n",
       "\n",
       "    weekday_is_friday  weekday_is_saturday  weekday_is_sunday  is_weekend  \\\n",
       "0                 0.0                  0.0                0.0         0.0   \n",
       "1                 0.0                  0.0                0.0         0.0   \n",
       "2                 0.0                  0.0                0.0         0.0   \n",
       "3                 0.0                  0.0                0.0         0.0   \n",
       "4                 0.0                  0.0                0.0         0.0   \n",
       "5                 0.0                  0.0                0.0         0.0   \n",
       "6                 0.0                  0.0                0.0         0.0   \n",
       "7                 0.0                  0.0                0.0         0.0   \n",
       "8                 0.0                  0.0                0.0         0.0   \n",
       "9                 0.0                  0.0                0.0         0.0   \n",
       "10                0.0                  0.0                0.0         0.0   \n",
       "11                0.0                  0.0                0.0         0.0   \n",
       "12                0.0                  0.0                0.0         0.0   \n",
       "13                0.0                  0.0                0.0         0.0   \n",
       "14                0.0                  0.0                0.0         0.0   \n",
       "\n",
       "      LDA_00    LDA_01    LDA_02    LDA_03    LDA_04  global_subjectivity  \\\n",
       "0   0.500331  0.378279  0.040005  0.041263  0.040123             0.521617   \n",
       "1   0.799756  0.050047  0.050096  0.050101  0.050001             0.341246   \n",
       "2   0.217792  0.033334  0.033351  0.033334  0.682188             0.702222   \n",
       "3   0.028573  0.419300  0.494651  0.028905  0.028572             0.429850   \n",
       "4   0.028633  0.028794  0.028575  0.028572  0.885427             0.513502   \n",
       "5   0.022245  0.306718  0.022231  0.022224  0.626582             0.437409   \n",
       "6   0.020082  0.114705  0.020024  0.020015  0.825173             0.514480   \n",
       "7   0.022224  0.150733  0.243435  0.022224  0.561384             0.543474   \n",
       "8   0.458250  0.028979  0.028662  0.029696  0.454412             0.538889   \n",
       "9   0.040000  0.040000  0.839997  0.040001  0.040002             0.313889   \n",
       "10  0.025004  0.287301  0.400829  0.261864  0.025002             0.482060   \n",
       "11  0.028628  0.028573  0.028596  0.028715  0.885488             0.477165   \n",
       "12  0.150493  0.025934  0.025188  0.304298  0.494088             0.534950   \n",
       "13  0.033386  0.033427  0.033352  0.866499  0.033337             0.509744   \n",
       "14  0.028780  0.028814  0.028574  0.885144  0.028687             0.295175   \n",
       "\n",
       "    global_sentiment_polarity  global_rate_positive_words  \\\n",
       "0                    0.092562                    0.045662   \n",
       "1                    0.148948                    0.043137   \n",
       "2                    0.323333                    0.056872   \n",
       "3                    0.100705                    0.041431   \n",
       "4                    0.281003                    0.074627   \n",
       "5                    0.071184                    0.029730   \n",
       "6                    0.268303                    0.080208   \n",
       "7                    0.298613                    0.083923   \n",
       "8                    0.161111                    0.030928   \n",
       "9                    0.051852                    0.038961   \n",
       "10                   0.102350                    0.038462   \n",
       "11                   0.150000                    0.026738   \n",
       "12                   0.100728                    0.051095   \n",
       "13                  -0.053085                    0.028070   \n",
       "14                   0.057299                    0.015444   \n",
       "\n",
       "    global_rate_negative_words  rate_positive_words  rate_negative_words  \\\n",
       "0                     0.013699             0.769231             0.230769   \n",
       "1                     0.015686             0.733333             0.266667   \n",
       "2                     0.009479             0.857143             0.142857   \n",
       "3                     0.020716             0.666667             0.333333   \n",
       "4                     0.012127             0.860215             0.139785   \n",
       "5                     0.027027             0.523810             0.476190   \n",
       "6                     0.016667             0.827957             0.172043   \n",
       "7                     0.015167             0.846939             0.153061   \n",
       "8                     0.020619             0.600000             0.400000   \n",
       "9                     0.030303             0.562500             0.437500   \n",
       "10                    0.020833             0.648649             0.351351   \n",
       "11                    0.010695             0.714286             0.285714   \n",
       "12                    0.029197             0.636364             0.363636   \n",
       "13                    0.052632             0.347826             0.652174   \n",
       "14                    0.011583             0.571429             0.428571   \n",
       "\n",
       "    avg_positive_polarity  min_positive_polarity  max_positive_polarity  \\\n",
       "0                0.378636               0.100000                    0.7   \n",
       "1                0.286915               0.033333                    0.7   \n",
       "2                0.495833               0.100000                    1.0   \n",
       "3                0.385965               0.136364                    0.8   \n",
       "4                0.411127               0.033333                    1.0   \n",
       "5                0.350610               0.136364                    0.6   \n",
       "6                0.402039               0.100000                    1.0   \n",
       "7                0.427720               0.100000                    1.0   \n",
       "8                0.566667               0.400000                    0.8   \n",
       "9                0.298413               0.100000                    0.5   \n",
       "10               0.404480               0.100000                    1.0   \n",
       "11               0.435000               0.200000                    0.7   \n",
       "12               0.375510               0.200000                    0.7   \n",
       "13               0.457500               0.160000                    1.0   \n",
       "14               0.249091               0.136364                    0.5   \n",
       "\n",
       "    avg_negative_polarity  min_negative_polarity  max_negative_polarity  \\\n",
       "0               -0.350000                -0.6000              -0.200000   \n",
       "1               -0.118750                -0.1250              -0.100000   \n",
       "2               -0.466667                -0.8000              -0.133333   \n",
       "3               -0.369697                -0.6000              -0.166667   \n",
       "4               -0.220192                -0.5000              -0.050000   \n",
       "5               -0.195000                -0.4000              -0.100000   \n",
       "6               -0.224479                -0.5000              -0.050000   \n",
       "7               -0.242778                -0.5000              -0.050000   \n",
       "8               -0.125000                -0.1250              -0.125000   \n",
       "9               -0.238095                -0.5000              -0.100000   \n",
       "10              -0.415064                -1.0000              -0.100000   \n",
       "11              -0.262500                -0.4000              -0.125000   \n",
       "12              -0.310417                -0.6000              -0.050000   \n",
       "13              -0.337889                -0.7000              -0.100000   \n",
       "14              -0.138690                -0.1875              -0.050000   \n",
       "\n",
       "    title_subjectivity  title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0             0.500000                 -0.187500                0.000000   \n",
       "1             0.000000                  0.000000                0.500000   \n",
       "2             0.000000                  0.000000                0.500000   \n",
       "3             0.000000                  0.000000                0.500000   \n",
       "4             0.454545                  0.136364                0.045455   \n",
       "5             0.642857                  0.214286                0.142857   \n",
       "6             0.000000                  0.000000                0.500000   \n",
       "7             1.000000                  0.500000                0.500000   \n",
       "8             0.125000                  0.000000                0.375000   \n",
       "9             0.000000                  0.000000                0.500000   \n",
       "10            0.000000                  0.000000                0.500000   \n",
       "11            0.000000                  0.000000                0.500000   \n",
       "12            1.000000                 -1.000000                0.500000   \n",
       "13            1.000000                 -1.000000                0.500000   \n",
       "14            0.750000                  0.550000                0.250000   \n",
       "\n",
       "    abs_title_sentiment_polarity   shares  \n",
       "0                       0.187500    593.0  \n",
       "1                       0.000000    711.0  \n",
       "2                       0.000000   1500.0  \n",
       "3                       0.000000   1200.0  \n",
       "4                       0.136364    505.0  \n",
       "5                       0.214286    855.0  \n",
       "6                       0.000000    556.0  \n",
       "7                       0.500000    891.0  \n",
       "8                       0.000000   3600.0  \n",
       "9                       0.000000    710.0  \n",
       "10                      0.000000   2200.0  \n",
       "11                      0.000000   1900.0  \n",
       "12                      1.000000    823.0  \n",
       "13                      1.000000  10000.0  \n",
       "14                      0.550000    761.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Print a table with the first 15 samples;\n",
    "online_news_popularity[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1c8e5f",
   "metadata": {},
   "source": [
    "In the next cell I show the histogram distribution of \"shares\", but in the first image the values on the y axis have a very large range, and therefore some values are not shown adequately, to solve this problem we plot on a logarithmic scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eafcf63a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T09:48:34.620413Z",
     "iopub.status.busy": "2022-01-05T09:48:34.619655Z",
     "iopub.status.idle": "2022-01-05T09:48:36.111720Z",
     "shell.execute_reply": "2022-01-05T09:48:36.110830Z",
     "shell.execute_reply.started": "2022-01-05T09:48:34.620365Z"
    },
    "id": "cbh1vpHDwuce",
    "outputId": "87db394b-40d3-4a4f-e3ee-40438754fd19"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEICAYAAABfz4NwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAan0lEQVR4nO3df5Bd5X3f8ffHEgaCLX4ujCxBhI3aMTC1MIoix+2UGtvI+IfwDLRiaiOnZOTBOGO3ThzkpBN7JkogiY2HNtBg4yDwD1Bkx1Db1KZgT5qWCq8TDAhQ2BiK1ihobX4Y3MBU4ts/7rPR3eVq9+6upBXS+zVz5p77Pec59zmPYD/3nHPvPakqJEl6xWx3QJK0fzAQJEmAgSBJagwESRJgIEiSGgNBkgQYCNJ+JUklOWW2+6GDk4Gg/VaSR5P8Q5LnuqbX7IFtvnVP9XEar39Uki8k+fskzyb52yS/NVv9kbrNne0OSJN4d1X999nuxKgkc6tqxww2cSVwBPB64BngnwCn74m+ddsD/dRByCMEvewkOTLJdUm2Jflxkt9LMqcte12SO5P8NMlPknwpyVFt2Y3AScB/bUcbH09yVpLhcdv/x6OIJJ9MsjHJF5P8DPjARK/fh18CvlxVT1XVi1X1UFVtHLfOW5M8nOSpJH+SJJPtW1e/fyvJvcDPk8xNsjzJ/0rydJIfJjmra/0PJPlRO1J5JMm/7fsfQQckA0EvR+uBHcApwBnA24Ffa8sC/AHwGjrvwk8EPglQVe8HHqNz1PGqqvrDPl9vJbAROAr40kSvn+Sk9sf3pN1s638D65L8apLFu1nnXXSC4w3AvwbOmWzfulwIvLP19QTgm8DvAccAvwF8NclAkiOAq4B3VNWrgV8B7pl0JHRAMxC0v/t6+wP7dJKvJzkBeAfw0ar6eVVtp3MaZhVAVQ1V1e1V9UJVjQCfAf7lDPtwV1V9vapeBOZN8vqPVdVRVfXYbrb163RC5cPAA0mGkrxj3DqXV9XTbRvfBZZMYd+uqqqtVfUPwPuAb1XVt9rRyO3AIHBuW/dF4PQkh1fVtqraPN0B0oHBawja353XfQ0hyTLgEGBbO5MCnTc2W9vy4+m88/0XwKvbsqdm2IetXfO/ONHrT6b9of594PeTzAMuA/48yUlV9WRb7e+7mvxf4FXQ976N7+sFSd7dVTsE+G5V/TzJv6Fz1HBdkv8JfKyqHupnP3Rg8ghBLzdbgReA49o78aOqal5VndaW/wFQwD+rqnl03iWnq/34n/f9OfALo0/atYCBcet0t5ns9ftWVT+jEw5HACf30WSyfevV1xu7+nlUVR1RVZe31/92Vb0NmA88BHxuqvugA4uBoJeVqtoGfAf4dJJ5SV7RLraOnjp5NfAc8HSSBcBvjtvEE8Bru57/LXBYkncmOQT4HeDQGbz+hJL8xyS/lOSVSQ4DPgI8DWzpo/lk+zbeF4F3JzknyZwkh7WL6AuTnJDkPe1awgttuzv72QcduAwEvRxdBLwSeIDOKZONdN7lAnwKeCOdj3R+E/jauLZ/APxOuybxG1X1DPAh4PPAj+kcMQwzsd2+fruo/NwEF5UL+DPgJ8DjwNuAd1bVc33s92T7NvaFqrbSuSD+CWCEzhHDb9L5//4VwMdaH56kcy3iQ330QQeweIMcSRJ4hCBJagwESRJgIEiSGgNBkgS8jL+Ydtxxx9WiRYtmuxuS9LLygx/84CdVNf67NsDLOBAWLVrE4ODgbHdDkl5Wkvyf3S3zlJEkCTAQJEmNgSBJAqYQCO23UP4myTfa82OS3N5u5HF7kqO71l3bftZ3S5JzuupnJrmvLbuq68Yfhya5udU3JVm0B/dRktSHqRwhfAR4sOv5ZcAdVbUYuKM9J8mpdH4b/jRgBXB1192krgHWAIvbtKLVLwaeqqpT6Py2/BXT2htJ0rT1FQhJFtK5C9Pnu8or6dw5ivZ4Xlf9pnYTj0eAIWBZkvnAvKq6qzo/oHTDuDaj29oInD169CBJ2jf6PUL4LPBxOndYGnVC+yng0Z8EPr7VFzD2Jh3DrbaAsb8iOVof06bdGPwZ4NjxnUiyJslgksGRkZE+uy5J6sekgZDkXcD2qvpBn9vs9c6+JqhP1GZsoeraqlpaVUsHBnp+r0KSNE39fDHtzcB7kpwLHAbMS/JF4Ikk86tqWzsdtL2tP0zn5t+jFtL5zfXhNj++3t1mOMlc4Eg6v9EuSdpHJg2EqloLrAVIchbwG1X1viR/BKwGLm+Pt7QmtwJfTvIZ4DV0Lh7fXVU7kzybZDmwic5NRv5TV5vVwF3A+cCdtRdv1LDosm/urU1P6tHL3zlrry1JE5nJT1dcDmxIcjHwGHABQFVtTrKBzt2kdgCXVtXorfkuAa4HDgduaxPAdcCNSYboHBmsmkG/JEnTMKVAqKrvAd9r8z8Fzt7NeuuAdT3qg8DpPerP0wJFkjQ7/KayJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJ6CMQkhyW5O4kP0yyOcmnWv2TSX6c5J42ndvVZm2SoSRbkpzTVT8zyX1t2VVJ0uqHJrm51TclWbQX9lWSNIF+jhBeAN5SVW8AlgArkixvy66sqiVt+hZAklPp3BP5NGAFcHWSOW39a4A1wOI2rWj1i4GnquoU4ErgihnvmSRpSiYNhOp4rj09pE01QZOVwE1V9UJVPQIMAcuSzAfmVdVdVVXADcB5XW3Wt/mNwNmjRw+SpH2jr2sISeYkuQfYDtxeVZvaog8nuTfJF5Ic3WoLgK1dzYdbbUGbH18f06aqdgDPAMdOfXckSdPVVyBU1c6qWgIspPNu/3Q6p39eR+c00jbg0231Xu/sa4L6RG3GSLImyWCSwZGRkX66Lknq05Q+ZVRVTwPfA1ZU1RMtKF4EPgcsa6sNAyd2NVsIPN7qC3vUx7RJMhc4Eniyx+tfW1VLq2rpwMDAVLouSZpEP58yGkhyVJs/HHgr8FC7JjDqvcD9bf5WYFX75NDJdC4e311V24Bnkyxv1wcuAm7parO6zZ8P3NmuM0iS9pG5fawzH1jfPin0CmBDVX0jyY1JltA5tfMo8EGAqtqcZAPwALADuLSqdrZtXQJcDxwO3NYmgOuAG5MM0TkyWDXzXZMkTcWkgVBV9wJn9Ki/f4I264B1PeqDwOk96s8DF0zWF0nS3uM3lSVJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSpMRAkSYCBIElqJg2EJIcluTvJD5NsTvKpVj8mye1JHm6PR3e1WZtkKMmWJOd01c9Mcl9bdlWStPqhSW5u9U1JFu2FfZUkTaCfI4QXgLdU1RuAJcCKJMuBy4A7qmoxcEd7TpJTgVXAacAK4Ookc9q2rgHWAIvbtKLVLwaeqqpTgCuBK2a+a5KkqZg0EKrjufb0kDYVsBJY3+rrgfPa/Ergpqp6oaoeAYaAZUnmA/Oq6q6qKuCGcW1Gt7UROHv06EGStG/0dQ0hyZwk9wDbgdurahNwQlVtA2iPx7fVFwBbu5oPt9qCNj++PqZNVe0AngGO7dGPNUkGkwyOjIz0tYOSpP70FQhVtbOqlgAL6bzbP32C1Xu9s68J6hO1Gd+Pa6tqaVUtHRgYmKTXkqSpmNKnjKrqaeB7dM79P9FOA9Eet7fVhoETu5otBB5v9YU96mPaJJkLHAk8OZW+SZJmpp9PGQ0kOarNHw68FXgIuBVY3VZbDdzS5m8FVrVPDp1M5+Lx3e200rNJlrfrAxeNazO6rfOBO9t1BknSPjK3j3XmA+vbJ4VeAWyoqm8kuQvYkORi4DHgAoCq2pxkA/AAsAO4tKp2tm1dAlwPHA7c1iaA64AbkwzROTJYtSd2TpLUv0kDoaruBc7oUf8pcPZu2qwD1vWoDwIvuf5QVc/TAkWSNDv8prIkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAno757KJyb5bpIHk2xO8pFW/2SSHye5p03ndrVZm2QoyZYk53TVz0xyX1t2Vbu3Mu3+yze3+qYki/bCvkqSJtDPEcIO4GNV9XpgOXBpklPbsiurakmbvgXQlq0CTgNWAFe3+zEDXAOsARa3aUWrXww8VVWnAFcCV8x81yRJUzFpIFTVtqr66zb/LPAgsGCCJiuBm6rqhap6BBgCliWZD8yrqruqqoAbgPO62qxv8xuBs0ePHiRJ+8aUriG0UzlnAJta6cNJ7k3yhSRHt9oCYGtXs+FWW9Dmx9fHtKmqHcAzwLE9Xn9NksEkgyMjI1PpuiRpEn0HQpJXAV8FPlpVP6Nz+ud1wBJgG/Dp0VV7NK8J6hO1GVuouraqllbV0oGBgX67LknqQ1+BkOQQOmHwpar6GkBVPVFVO6vqReBzwLK2+jBwYlfzhcDjrb6wR31MmyRzgSOBJ6ezQ5Kk6ennU0YBrgMerKrPdNXnd632XuD+Nn8rsKp9cuhkOheP766qbcCzSZa3bV4E3NLVZnWbPx+4s11nkCTtI3P7WOfNwPuB+5Lc02qfAC5MsoTOqZ1HgQ8CVNXmJBuAB+h8QunSqtrZ2l0CXA8cDtzWJugEzo1JhugcGayayU5JkqZu0kCoqr+i9zn+b03QZh2wrkd9EDi9R/154ILJ+iJJ2nv8prIkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAno757KJyb5bpIHk2xO8pFWPybJ7Ukebo9Hd7VZm2QoyZYk53TVz0xyX1t2Vbu3Mu3+yze3+qYki/bCvkqSJtDPEcIO4GNV9XpgOXBpklOBy4A7qmoxcEd7Tlu2CjgNWAFcnWRO29Y1wBpgcZtWtPrFwFNVdQpwJXDFHtg3SdIUTBoIVbWtqv66zT8LPAgsAFYC69tq64Hz2vxK4KaqeqGqHgGGgGVJ5gPzququqirghnFtRre1ETh79OhBkrRvTOkaQjuVcwawCTihqrZBJzSA49tqC4CtXc2GW21Bmx9fH9OmqnYAzwDH9nj9NUkGkwyOjIxMpeuSpEn0HQhJXgV8FfhoVf1solV71GqC+kRtxhaqrq2qpVW1dGBgYLIuS5KmoK9ASHIInTD4UlV9rZWfaKeBaI/bW30YOLGr+ULg8VZf2KM+pk2SucCRwJNT3RlJ0vT18ymjANcBD1bVZ7oW3QqsbvOrgVu66qvaJ4dOpnPx+O52WunZJMvbNi8a12Z0W+cDd7brDJKkfWRuH+u8GXg/cF+Se1rtE8DlwIYkFwOPARcAVNXmJBuAB+h8QunSqtrZ2l0CXA8cDtzWJugEzo1JhugcGaya2W5JkqZq0kCoqr+i9zl+gLN302YdsK5HfRA4vUf9eVqgSJJmh99UliQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSpMRAkSYCBIElqDARJEmAgSJIaA0GSBBgIkqTGQJAkAf3dU/kLSbYnub+r9skkP05yT5vO7Vq2NslQki1Jzumqn5nkvrbsqnZfZdq9l29u9U1JFu3hfZQk9aGfI4TrgRU96ldW1ZI2fQsgyal07od8WmtzdZI5bf1rgDXA4jaNbvNi4KmqOgW4ErhimvsiSZqBSQOhqv6Szo3v+7ESuKmqXqiqR4AhYFmS+cC8qrqrqgq4ATivq836Nr8ROHv06EGStO/M5BrCh5Pc204pHd1qC4CtXesMt9qCNj++PqZNVe0AngGO7fWCSdYkGUwyODIyMoOuS5LGm24gXAO8DlgCbAM+3eq93tnXBPWJ2ry0WHVtVS2tqqUDAwNT6rAkaWLTCoSqeqKqdlbVi8DngGVt0TBwYteqC4HHW31hj/qYNknmAkfS/ykqSdIeMq1AaNcERr0XGP0E0q3AqvbJoZPpXDy+u6q2Ac8mWd6uD1wE3NLVZnWbPx+4s11nkCTtQ3MnWyHJV4CzgOOSDAO/C5yVZAmdUzuPAh8EqKrNSTYADwA7gEuramfb1CV0PrF0OHBbmwCuA25MMkTnyGDVHtgvSdIUTRoIVXVhj/J1E6y/DljXoz4InN6j/jxwwWT9kCTtXX5TWZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSpMRAkSYCBIElqDARJEmAgSJIaA0GSBPQRCEm+kGR7kvu7asckuT3Jw+3x6K5la5MMJdmS5Jyu+plJ7mvLrmr3Vqbdf/nmVt+UZNEe3kdJUh/6OUK4HlgxrnYZcEdVLQbuaM9JciqdeyKf1tpcnWROa3MNsAZY3KbRbV4MPFVVpwBXAldMd2ckSdM3aSBU1V8CT44rrwTWt/n1wHld9Zuq6oWqegQYApYlmQ/Mq6q7qqqAG8a1Gd3WRuDs0aMHSdK+M91rCCdU1TaA9nh8qy8AtnatN9xqC9r8+PqYNlW1A3gGOLbXiyZZk2QwyeDIyMg0uy5J6mVPX1Tu9c6+JqhP1Oalxaprq2ppVS0dGBiYZhclSb1MNxCeaKeBaI/bW30YOLFrvYXA462+sEd9TJskc4EjeekpKknSXjbdQLgVWN3mVwO3dNVXtU8OnUzn4vHd7bTSs0mWt+sDF41rM7qt84E723UGSdI+NHeyFZJ8BTgLOC7JMPC7wOXAhiQXA48BFwBU1eYkG4AHgB3ApVW1s23qEjqfWDocuK1NANcBNyYZonNksGqP7JkkaUomDYSqunA3i87ezfrrgHU96oPA6T3qz9MCRZI0e/ymsiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCZhhICR5NMl9Se5JMthqxyS5PcnD7fHorvXXJhlKsiXJOV31M9t2hpJc1e67LEnah/bEEcK/qqolVbW0Pb8MuKOqFgN3tOckOZXO/ZJPA1YAVyeZ09pcA6wBFrdpxR7olyRpCvbGKaOVwPo2vx44r6t+U1W9UFWPAEPAsiTzgXlVdVdVFXBDVxtJ0j4y00Ao4DtJfpBkTaudUFXbANrj8a2+ANja1Xa41Ra0+fF1SdI+NHeG7d9cVY8nOR64PclDE6zb67pATVB/6QY6obMG4KSTTppqXyVJE5jREUJVPd4etwN/ASwDnmingWiP29vqw8CJXc0XAo+3+sIe9V6vd21VLa2qpQMDAzPpuiRpnGkHQpIjkrx6dB54O3A/cCuwuq22Grilzd8KrEpyaJKT6Vw8vrudVno2yfL26aKLutpIkvaRmZwyOgH4i/YJ0bnAl6vqvyX5PrAhycXAY8AFAFW1OckG4AFgB3BpVe1s27oEuB44HLitTZKkfWjagVBVPwLe0KP+U+Ds3bRZB6zrUR8ETp9uXyRJM+c3lSVJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSpMRAkSYCBIElq9ptASLIiyZYkQ0kum+3+SNLBZr8IhCRzgD8B3gGcClyY5NTZ7ZUkHVzmznYHmmXAUFX9CCDJTcBK4IFZ7dVesOiyb87K6z56+Ttn5XUlvXzsL4GwANja9XwY+OXxKyVZA6xpT59LsmWar3cc8JNptn1ZyhVTWv2gG59pcIwm5vhMbDbH5xd3t2B/CYT0qNVLClXXAtfO+MWSwapaOtPtHKgcn8k5RhNzfCa2v47PfnENgc4RwYldzxcCj89SXyTpoLS/BML3gcVJTk7ySmAVcOss90mSDir7xSmjqtqR5MPAt4E5wBeqavNefMkZn3Y6wDk+k3OMJub4TGy/HJ9UveRUvSTpILS/nDKSJM0yA0GSBByEgXAg/0RGkhOTfDfJg0k2J/lIqx+T5PYkD7fHo7varG1jsSXJOV31M5Pc15ZdlSStfmiSm1t9U5JFXW1Wt9d4OMnqfbjrU5JkTpK/SfKN9tzxaZIclWRjkofaf0dvcnzGSvLv2/9f9yf5SpLDDpgxqqqDZqJzwfrvgNcCrwR+CJw62/3ag/s3H3hjm3818Ld0fgrkD4HLWv0y4Io2f2obg0OBk9vYzGnL7gbeROc7IrcB72j1DwH/pc2vAm5u88cAP2qPR7f5o2d7THYzTv8B+DLwjfbc8dk1NuuBX2vzrwSOcnzGjM8C4BHg8PZ8A/CBA2WMZn2A9/E/5puAb3c9Xwusne1+7cX9vQV4G7AFmN9q84Etvfafzqe83tTWeairfiHwp93rtPm5dL5tme512rI/BS6c7THoMSYLgTuAt7ArEByfTp/mtT92GVd3fHb1a/RXFY5p/f8G8PYDZYwOtlNGvX4iY8Es9WWvaoeZZwCbgBOqahtAezy+rba78VjQ5sfXx7Spqh3AM8CxE2xrf/NZ4OPAi101x6fjtcAI8GftlNrnkxyB4/OPqurHwB8DjwHbgGeq6jscIGN0sAVCXz+R8XKX5FXAV4GPVtXPJlq1R60mqE+3zX4hybuA7VX1g36b9KgdsOND593oG4FrquoM4Od0Tn/szsE2PrRrAyvpnP55DXBEkvdN1KRHbb8do4MtEA74n8hIcgidMPhSVX2tlZ9IMr8tnw9sb/Xdjcdwmx9fH9MmyVzgSODJCba1P3kz8J4kjwI3AW9J8kUcn1HDwHBVbWrPN9IJCMdnl7cCj1TVSFX9P+BrwK9woIzRbJ+T28fn/+bSuRBzMrsuKp822/3ag/sX4Abgs+Pqf8TYC15/2OZPY+wFrx+x64LX94Hl7LrgdW6rX8rYC14b2vwxdM4/H92mR4BjZntMJhirs9h1DcHx2TUu/wP4p23+k21sHJ9d4/PLwGbgF9q+rQd+/UAZo1kf4Fn4Bz2Xzqdv/g747dnuzx7et39O5xDyXuCeNp1L5/zjHcDD7fGYrja/3cZiC+1TDq2+FLi/LfvP7PpW+2HAnwNDdD4l8dquNv+u1YeAX53t8ZhkrM5iVyA4Prv6uAQYbP8Nfb394XF8xo7Rp4CH2v7dSOeP/QExRv50hSQJOPiuIUiSdsNAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSmv8Phxv/gEdEUw0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3) Plot the histogram distribution of \"shares\";\n",
    "\n",
    "# Incorrect plot\n",
    "plt.hist(online_news_popularity[\"shares\"])\n",
    "plt.title(\"Feature: Shares\")\n",
    "plt.show()\n",
    "\n",
    "# Correct plot\n",
    "plt.hist(online_news_popularity[\"shares\"])\n",
    "plt.title(\"Feature: Shares (log scale) Before\")\n",
    "# The values on the y axis have a very large range, to solve this problem we plot on a logarithmic scale\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "# Correct plot after scale\n",
    "quantile_transformer = preprocessing.QuantileTransformer(random_state=0,n_quantiles=112, output_distribution='normal')\n",
    "onp_reshaped = np.array(online_news_popularity['shares']).reshape(-1, 1)\n",
    "onp_qtrans = quantile_transformer.fit_transform(onp_reshaped)\n",
    "plt.hist(onp_qtrans)\n",
    "plt.title(\"Feature: Shares (log scale) After\")\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b548d8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T09:48:36.114270Z",
     "iopub.status.busy": "2022-01-05T09:48:36.113317Z",
     "iopub.status.idle": "2022-01-05T09:48:36.548132Z",
     "shell.execute_reply": "2022-01-05T09:48:36.547235Z",
     "shell.execute_reply.started": "2022-01-05T09:48:36.114223Z"
    },
    "id": "JaRDtZFrwuce",
    "outputId": "704466b6-8328-4666-e269-9855d26322a4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4) A bar chart counting the attributes:  data_channel_is_lifestyle, data_channel_is_entertainment, \n",
    "#   data_channel_is_bus, data_channel_is_socmed, data_channel_is_tech, data_channel_is_world;\n",
    "\n",
    "# List of required attributes\n",
    "attributes = [\"data_channel_is_lifestyle\", \"data_channel_is_entertainment\", \"data_channel_is_bus\", \n",
    "                \"data_channel_is_socmed\", \"data_channel_is_tech\", \"data_channel_is_world\"]\n",
    "\n",
    "# Arrays used to store the total number of Boolean values for each feature\n",
    "total_zero = []\n",
    "total_one = []\n",
    "\n",
    "for attribute in attributes:\n",
    "    total_zero.append(onp_bin[attribute].value_counts()[0]) # zero\n",
    "    total_one.append(onp_bin[attribute].value_counts()[1])  # one\n",
    "\n",
    "# Declaring the figure or the plot (y, x) or (width, height)\n",
    "plt.figure(figsize=[20, 10])\n",
    "\n",
    "# Using numpy to group different data with bars\n",
    "number_list = np.arange(len(total_zero))\n",
    "\n",
    "for attribute in attributes:\n",
    "    plt.bar(number_list, total_zero, color = 'orange', width = 0.35)\n",
    "    plt.bar(number_list + 0.35, total_one, color = 'blue', width = 0.35)\n",
    "    \n",
    "# Creating the legend of the bars in the plot\n",
    "plt.legend(['0', '1'])\n",
    "\n",
    "# Overiding the x axis with the feature names\n",
    "plt.xticks([i + 0.35 for i in range(len(attributes))], attributes)\n",
    "\n",
    "# Giving the tilte for the plot\n",
    "plt.title(\"A bar chart counting the boolean value\")\n",
    "\n",
    "# Namimg the x and y axis\n",
    "plt.xlabel('Attributes')\n",
    "plt.ylabel('Tot')\n",
    "\n",
    "# Saving the plot as a 'png'\n",
    "#plt.savefig('4BarPlot.png')\n",
    "\n",
    "# Displaying the bar plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedeca32",
   "metadata": {
    "id": "21ieszFxwucf"
   },
   "source": [
    "## 2.3 Feature importance analysis  (up to 1 of 11.2 points)\n",
    "\n",
    "Perform feature importance analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2879133a",
   "metadata": {
    "id": "0rycUEyvwucf"
   },
   "source": [
    "To analyze the importance of the features I decided to use the \"permutation_importance\" function, as it allows you to permute a feature several times thanks to the \"n_repeat\" attribute, thus being more precise than the simple \"feature_importances_\" attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "526cae28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T09:48:36.549703Z",
     "iopub.status.busy": "2022-01-05T09:48:36.549260Z",
     "iopub.status.idle": "2022-01-05T09:50:16.400091Z",
     "shell.execute_reply": "2022-01-05T09:50:16.399154Z",
     "shell.execute_reply.started": "2022-01-05T09:48:36.549669Z"
    },
    "id": "wZCVGIT4wucf",
    "outputId": "4fca7ec4-9f56-421c-a247-b984c84bcf8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.106 +/- 0.001 kw_avg_avg\n",
      "0.071 +/- 0.001 self_reference_min_shares\n",
      "0.059 +/- 0.001 kw_max_avg\n",
      "0.050 +/- 0.001 LDA_03\n",
      "0.045 +/- 0.001 timedelta\n",
      "0.043 +/- 0.001 self_reference_avg_sharess\n",
      "0.041 +/- 0.001 LDA_04\n",
      "0.032 +/- 0.001 kw_min_avg\n",
      "0.030 +/- 0.001 LDA_02\n",
      "0.025 +/- 0.001 is_weekend\n",
      "0.024 +/- 0.001 LDA_00\n",
      "0.021 +/- 0.000 self_reference_max_shares\n",
      "0.020 +/- 0.001 data_channel_is_entertainment\n",
      "0.019 +/- 0.000 LDA_01\n",
      "0.019 +/- 0.001 n_unique_tokens\n",
      "0.019 +/- 0.000 data_channel_is_world\n",
      "0.017 +/- 0.001 num_hrefs\n",
      "0.017 +/- 0.001 kw_avg_min\n",
      "0.017 +/- 0.001 kw_avg_max\n",
      "0.016 +/- 0.001 data_channel_is_tech\n",
      "0.015 +/- 0.001 kw_min_max\n",
      "0.013 +/- 0.000 n_tokens_content\n",
      "0.013 +/- 0.000 n_non_stop_unique_tokens\n",
      "0.012 +/- 0.001 average_token_length\n",
      "0.011 +/- 0.001 kw_max_min\n",
      "0.011 +/- 0.001 global_subjectivity\n",
      "0.010 +/- 0.000 global_sentiment_polarity\n",
      "0.009 +/- 0.000 avg_negative_polarity\n",
      "0.009 +/- 0.001 global_rate_positive_words\n",
      "0.009 +/- 0.000 global_rate_negative_words\n",
      "0.009 +/- 0.000 num_imgs\n",
      "0.008 +/- 0.001 rate_positive_words\n",
      "0.008 +/- 0.001 avg_positive_polarity\n",
      "0.008 +/- 0.000 n_non_stop_words\n",
      "0.008 +/- 0.001 rate_negative_words\n",
      "0.007 +/- 0.001 n_tokens_title\n",
      "0.007 +/- 0.001 min_positive_polarity\n",
      "0.007 +/- 0.000 max_positive_polarity\n",
      "0.007 +/- 0.001 num_self_hrefs\n",
      "0.006 +/- 0.000 num_videos\n",
      "0.005 +/- 0.000 title_subjectivity\n",
      "0.005 +/- 0.001 abs_title_sentiment_polarity\n",
      "0.005 +/- 0.000 min_negative_polarity\n",
      "0.005 +/- 0.000 data_channel_is_socmed\n",
      "0.005 +/- 0.000 max_negative_polarity\n",
      "0.004 +/- 0.001 abs_title_subjectivity\n",
      "0.004 +/- 0.000 kw_min_min\n",
      "0.004 +/- 0.000 title_sentiment_polarity\n",
      "0.004 +/- 0.000 data_channel_is_bus\n",
      "0.004 +/- 0.000 weekday_is_saturday\n",
      "0.004 +/- 0.000 kw_max_max\n",
      "0.003 +/- 0.000 num_keywords\n",
      "0.002 +/- 0.000 weekday_is_tuesday\n",
      "0.002 +/- 0.000 weekday_is_wednesday\n",
      "0.002 +/- 0.000 weekday_is_friday\n",
      "0.001 +/- 0.000 weekday_is_sunday\n",
      "0.001 +/- 0.000 weekday_is_thursday\n",
      "0.001 +/- 0.000 weekday_is_monday\n",
      "0.000 +/- 0.000 data_channel_is_lifestyle\n",
      "CPU times: user 1min 55s, sys: 28 ms, total: 1min 55s\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rfc_clf = RandomForestClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0)\n",
    "rfc_clf.fit(X_train, y_train)\n",
    "\n",
    "r = permutation_importance(rfc_clf, X, y, n_repeats=10, random_state=0)\n",
    "\n",
    "# Dict to store features and their importance\n",
    "less_important = {}\n",
    "\n",
    "for i in r.importances_mean.argsort()[::-1]:\n",
    "    less_important[onp_better.columns[i]] = r.importances_mean[i]\n",
    "    if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "        print(f\"{r.importances_mean[i]:.3f}\" f\" +/- {r.importances_std[i]:.3f} \" f\"{onp_better.columns[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e54f11f",
   "metadata": {},
   "source": [
    "To speed up the execution of the models in the next phase I decided to remove the less important features (with a value below 0.005, because through various tests I have noticed that by removing features with higher values there is a worsening of the accuracy for some models )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "58d25f23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T09:50:16.401888Z",
     "iopub.status.busy": "2022-01-05T09:50:16.401500Z",
     "iopub.status.idle": "2022-01-05T09:50:16.476346Z",
     "shell.execute_reply": "2022-01-05T09:50:16.475693Z",
     "shell.execute_reply.started": "2022-01-05T09:50:16.401845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  (44115, 59)\n",
      "After:  (44115, 44)\n"
     ]
    }
   ],
   "source": [
    "print(\"Before: \", X.shape)\n",
    "for col in less_important:\n",
    "    if less_important[col] < 0.005:\n",
    "        X.drop(col, axis=1, inplace=True)\n",
    "print(\"After: \", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b90f0299",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T09:50:16.478304Z",
     "iopub.status.busy": "2022-01-05T09:50:16.477545Z",
     "iopub.status.idle": "2022-01-05T09:50:16.796863Z",
     "shell.execute_reply": "2022-01-05T09:50:16.796009Z",
     "shell.execute_reply.started": "2022-01-05T09:50:16.478266Z"
    },
    "id": "1h-L4DIfwucf",
    "outputId": "69f17430-1ec3-45d4-9317-f0eadd6c004b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: kw_avg_avg  Index: 26  Value: 0.10632437946276778\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Features Importance with permutation_importance() function\n",
    "number_list = np.arange(len(r.importances_mean))\n",
    "plt.bar(number_list, r.importances_mean)\n",
    "print(\"Feature:\", onp_better.columns[np.argmax(r.importances_mean)], \" Index:\", np.argmax(r.importances_mean), \" Value:\", r.importances_mean[np.argmax(r.importances_mean)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "89980955",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T09:50:16.798195Z",
     "iopub.status.busy": "2022-01-05T09:50:16.797986Z",
     "iopub.status.idle": "2022-01-05T09:50:17.133513Z",
     "shell.execute_reply": "2022-01-05T09:50:17.132716Z",
     "shell.execute_reply.started": "2022-01-05T09:50:16.798169Z"
    },
    "id": "X-YqAkJXwucf",
    "outputId": "558e30fa-2cd7-4eca-f6b2-2fa5cd17dcf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: kw_avg_avg  Index: 26  Value: 0.03408278343125609\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Features Importance with the feature_importances_ parameter\n",
    "importance = rfc_clf.feature_importances_\n",
    "\n",
    "number_list = np.arange(len(importance))\n",
    "\n",
    "plt.bar(number_list, importance)\n",
    "print(\"Feature:\", onp_better.columns[np.argmax(importance)], \" Index:\", np.argmax(importance), \" Value:\", importance[np.argmax(importance)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99406da1",
   "metadata": {
    "id": "IevoTzJ7wucg"
   },
   "source": [
    "<hr>\n",
    "\n",
    "## 3. Model Selection (up to 8.2 of 11.2  points)\n",
    "In this part of the challenge you are requested to perform all the necessary steps required in order to design a full fledged classification task on the <b>shares</b> feature.\n",
    "\n",
    "You are requested to perform the following steps having in mind the following: \n",
    "\n",
    "1) the dataset must be properly splitted to perform crossvalidation \n",
    "\n",
    "2) when required, features must be properly encoded\n",
    "\n",
    "3) in order to simplify the problem the target feature can be dicretized <b>(number of classes must be >=5)</b> ;\n",
    "\n",
    "4) for model selection you are requested to consider: \n",
    "\n",
    "- Decision Trees\n",
    "\n",
    "- Support Vector Machines;\n",
    "\n",
    "- An ensamble methodology;\n",
    "\n",
    "- MLPNs.\n",
    "\n",
    "5) hyper-parameter tuning <b>must</b> be performed and discussed;\n",
    "\n",
    "6) apply standardizion and normalization when appropriate;\n",
    "\n",
    "7) remember to use an appropriate evaluation setting (cross-fold etc..)\n",
    "\n",
    "8) describe the measures adopted for the evaluation and discuss the results;\n",
    "\n",
    "9) provide a discussion of the model selection, where you describe the differences in terms of performance and explains the root causes;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fc2627",
   "metadata": {},
   "source": [
    "First of all, I split the dataset into two parts again (train and test set), because in the previous section I eliminated the less important features and define the names of the target classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "424eea97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T09:50:17.138755Z",
     "iopub.status.busy": "2022-01-05T09:50:17.138503Z",
     "iopub.status.idle": "2022-01-05T09:50:17.161576Z",
     "shell.execute_reply": "2022-01-05T09:50:17.160813Z",
     "shell.execute_reply.started": "2022-01-05T09:50:17.138728Z"
    },
    "id": "g43hXLuDwucg"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 112)\n",
    "\n",
    "# Class names of the target\n",
    "target_names = [ 'Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb8dfb5",
   "metadata": {},
   "source": [
    "In this section I will analyze 4 different models to predict the target class, i.e. Decision Tree Classifier, Support Vector Machines Classifier (SVM), Random Forest and Multi Layer Perceptron Networks (MLPN).\n",
    "\n",
    "Hyperparameter optimization will be performed for each model to find the best parameters. To do this I used two functions:\n",
    "- <i> GridSearchCV </i>, which exhaustively generates candidates from a grid of parameter values specified with the param_grid parameter;\n",
    "- <i> RandomiizedSearchCV </i>, which implements a randomized parameter search, in which each setting is sampled from a distribution on the possible values of the parameters.\n",
    "\n",
    "After that for each model I will show the confusion matrix and the classification report obtained from the previous model learned.\n",
    "\n",
    "Finally I perform the cross-validation with the <i> cross_val_score </i> function dividing the data, fitting a model and computing the score 5 consecutive times (with different splits each time), and then showing the maximum score and the average of all the scores obtained +/- the standard deviation, to reduce the probability of being \"lucky\" or \"unlucky\" in splitting the data into training set and test set.\n",
    "\n",
    "In addition, for each model I decided to print the time required for execution to show which model is the fastest, but also to demonstrate the long time it takes to execute everything."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e92c0e",
   "metadata": {
    "id": "q4C7yuiOwucg"
   },
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1b63d1",
   "metadata": {},
   "source": [
    "Decision Tree is a supervised machine learning algorithm that creates a tree structure, in which nodes are tests on feature values and leaf nodes are the \"decisions\" that specify the class label.\n",
    "\n",
    "Every test node is a test on the value (or range) of one features and for each possible outcome of the test, an edge is created that links to a subsequent test node or to a leaf node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e9fd84",
   "metadata": {
    "id": "TKMY-5uBwucg"
   },
   "source": [
    "##### Hyper-Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8467f861",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T09:50:17.162869Z",
     "iopub.status.busy": "2022-01-05T09:50:17.162671Z",
     "iopub.status.idle": "2022-01-05T09:51:46.129622Z",
     "shell.execute_reply": "2022-01-05T09:51:46.128699Z",
     "shell.execute_reply.started": "2022-01-05T09:50:17.162843Z"
    },
    "id": "20wchnIpwucg",
    "outputId": "c55a3002-d3d5-4a70-a7e0-3ae5868d4cd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 100}\n",
      "CPU times: user 2.3 s, sys: 182 ms, total: 2.48 s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dtc_parameter = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_samples_leaf': [2, 10, 25, 50, 100],\n",
    "    'max_depth': [5, 10, 50, 100]}\n",
    "\n",
    "dtc = GridSearchCV(tree.DecisionTreeClassifier(), dtc_parameter, n_jobs = -1) \n",
    "dtc.fit(X_train, y_train) \n",
    "dtc_best_params = dtc.best_params_\n",
    "print(\"Best parameters:\", dtc_best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a663f02a",
   "metadata": {
    "id": "ulA9-V2zwuch"
   },
   "source": [
    "##### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5816722d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T09:51:46.131636Z",
     "iopub.status.busy": "2022-01-05T09:51:46.131397Z",
     "iopub.status.idle": "2022-01-05T09:51:46.199573Z",
     "shell.execute_reply": "2022-01-05T09:51:46.198696Z",
     "shell.execute_reply.started": "2022-01-05T09:51:46.131602Z"
    },
    "id": "37auKWa-wuch",
    "outputId": "4813f542-9ed6-4841-f9ff-f8a40db1b9a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[1137  634  308  232  324]\n",
      " [ 760  775  402  342  353]\n",
      " [ 584  475  552  589  495]\n",
      " [ 436  436  456  691  588]\n",
      " [ 343  328  375  655  965]] \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.35      0.43      0.39      2635\n",
      "     Class 1       0.29      0.29      0.29      2632\n",
      "     Class 2       0.26      0.20      0.23      2695\n",
      "     Class 3       0.28      0.27      0.27      2607\n",
      "     Class 4       0.35      0.36      0.36      2666\n",
      "\n",
      "    accuracy                           0.31     13235\n",
      "   macro avg       0.31      0.31      0.31     13235\n",
      "weighted avg       0.31      0.31      0.31     13235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtc_predicted = dtc.predict(X_test)\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, dtc_predicted), \"\\n\")\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, dtc_predicted, target_names = target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12c63a6",
   "metadata": {},
   "source": [
    "The classes with the highest accuracy value are 0 and 4, but the former has a higher recall value, while the accuracy is 31%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf223d46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T09:51:46.201179Z",
     "iopub.status.busy": "2022-01-05T09:51:46.200939Z",
     "iopub.status.idle": "2022-01-05T09:51:49.403945Z",
     "shell.execute_reply": "2022-01-05T09:51:49.403049Z",
     "shell.execute_reply.started": "2022-01-05T09:51:46.201150Z"
    },
    "id": "pBRtjR--wuch",
    "outputId": "7ad359b5-e7aa-4ed0-fc03-b5266c203d65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Accuracy: 0.22  Mean Accuracy: 0.13 +/- 0.13\n",
      "CPU times: user 42.3 ms, sys: 10.1 ms, total: 52.4 ms\n",
      "Wall time: 3.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dtc_clf = tree.DecisionTreeClassifier(criterion = dtc_best_params['criterion'],\n",
    "                                    min_samples_leaf = dtc_best_params['min_samples_leaf'],\n",
    "                                    max_depth = dtc_best_params['max_depth'])\n",
    "\n",
    "dtc_scores = cross_val_score(dtc_clf, X, y, cv=5, n_jobs=-1)\n",
    "print(\"Max Accuracy:\", \"{:.2f}\".format(max(dtc_scores)), \" Mean Accuracy:\", \"{:.2f}\".format(dtc_scores.mean()), \"+/-\", \"{:.2f}\".format(dtc_scores.std()*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f702c711",
   "metadata": {},
   "source": [
    "By comparing the last two cells we can see how the accuracy obtained is lower than the accuracy we printed in the classification report (13% instead of 31%).\n",
    "This is because the cross-validation operation is used to reduce the probability of being unlucky and lucky by splitting the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba47ee6",
   "metadata": {
    "id": "Xe1kJM3wwuch"
   },
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cb50c6",
   "metadata": {},
   "source": [
    "SVM is a supervised machine learning algorithm and aims to find a hyperplane that separates instances well, called the decision boundary.\n",
    "\n",
    "The goal is to maximize the margin to avoid overfitting (small margin) or to have a more general model which leads to more classification errors.\n",
    "Margin is the width by which the boundary can be increased before reaching a data point in the learning set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c849b03",
   "metadata": {
    "id": "No9rAAOUwuch"
   },
   "source": [
    "##### Hyper-Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "840837bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T09:51:49.406276Z",
     "iopub.status.busy": "2022-01-05T09:51:49.405945Z",
     "iopub.status.idle": "2022-01-05T10:40:36.814604Z",
     "shell.execute_reply": "2022-01-05T10:40:36.813803Z",
     "shell.execute_reply.started": "2022-01-05T09:51:49.406223Z"
    },
    "id": "kDGgobrmwuch"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 100000, 'gamma': 1, 'kernel': 'linear'}\n",
      "CPU times: user 7min 25s, sys: 162 ms, total: 7min 25s\n",
      "Wall time: 48min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# I avoided using the \"rbf\" kernel because trying it took too long to run (over an afternoon).\n",
    "svm_parameters = {\n",
    "    'kernel': ['linear'],\n",
    "    'gamma': [1, 1e-1, 1e-2],\n",
    "    'C': [100, 1000, 100000]}\n",
    "\n",
    "svc = GridSearchCV(svm.SVC(), svm_parameters, n_jobs=-1)\n",
    "svc.fit(X_train, y_train)  \n",
    "\n",
    "svc_best_params = svc.best_params_\n",
    "print(\"Best parameters:\", svc_best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8e0f77",
   "metadata": {
    "id": "-NOKZdMVwuci"
   },
   "source": [
    "##### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e82f3fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T10:40:36.816058Z",
     "iopub.status.busy": "2022-01-05T10:40:36.815819Z",
     "iopub.status.idle": "2022-01-05T10:40:57.850877Z",
     "shell.execute_reply": "2022-01-05T10:40:57.850054Z",
     "shell.execute_reply.started": "2022-01-05T10:40:36.816030Z"
    },
    "id": "lVLWQLjiwuci"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[1546  326  167  216  380]\n",
      " [1112  535  219  359  407]\n",
      " [ 943  251  321  615  565]\n",
      " [ 613  266  233  863  632]\n",
      " [ 499  173  186  745 1063]] \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.33      0.59      0.42      2635\n",
      "     Class 1       0.34      0.20      0.26      2632\n",
      "     Class 2       0.29      0.12      0.17      2695\n",
      "     Class 3       0.31      0.33      0.32      2607\n",
      "     Class 4       0.35      0.40      0.37      2666\n",
      "\n",
      "    accuracy                           0.33     13235\n",
      "   macro avg       0.32      0.33      0.31     13235\n",
      "weighted avg       0.32      0.33      0.31     13235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_predicted = svc.predict(X_test) \n",
    "\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, svc_predicted), \"\\n\")\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, svc_predicted, target_names = target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f53c65",
   "metadata": {},
   "source": [
    "In this case we obtain an accuracy of 33% that is very similar to the accuracy obtained from DTC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "32b2e2b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T10:40:57.852799Z",
     "iopub.status.busy": "2022-01-05T10:40:57.852259Z",
     "iopub.status.idle": "2022-01-05T11:10:40.617854Z",
     "shell.execute_reply": "2022-01-05T11:10:40.616730Z",
     "shell.execute_reply.started": "2022-01-05T10:40:57.852754Z"
    },
    "id": "U6F6NikTwuci"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Accuracy: 0.32  Mean Accuracy: 0.29 +/- 0.06\n",
      "CPU times: user 160 ms, sys: 88.4 ms, total: 248 ms\n",
      "Wall time: 29min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "svc_clf = svm.SVC(kernel = svc_best_params['kernel'], gamma = svc_best_params['gamma'], C = svc_best_params['C'])\n",
    "\n",
    "svc_scores = cross_val_score(svc_clf, X, y, cv=5, n_jobs=-1)\n",
    "\n",
    "print(\"Max Accuracy:\", \"{:.2f}\".format(max(svc_scores)), \" Mean Accuracy:\", \"{:.2f}\".format(svc_scores.mean()), \"+/-\", \"{:.2f}\".format(svc_scores.std()*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34da396a",
   "metadata": {},
   "source": [
    "As for Decision Tree the accuracy obtained is lower than the accuracy we printed in the classification report (29% instead of 33%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6c7d51",
   "metadata": {
    "id": "4tUIyl3Iwuci"
   },
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637d445e",
   "metadata": {},
   "source": [
    "The ensemble method is a supervised machine learning algorithm consisting of a set of classifiers that learn a target function and their individual predictions are combined to classify new examples.\n",
    "Ensembles generally improve the generalization performance and reduces the variance of a set of classifiers on a domain.\n",
    "\n",
    "The algorithm used belonging to the category of essemble methods is the Random Forest which uses a set of d-trees and then chooses the final classification with a voting method such as Majority Voting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9895138",
   "metadata": {
    "id": "N7KqRx36wuci"
   },
   "source": [
    "##### Hyper-Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "68736fc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T11:25:03.584923Z",
     "iopub.status.busy": "2022-01-05T11:25:03.584554Z",
     "iopub.status.idle": "2022-01-05T11:51:59.721190Z",
     "shell.execute_reply": "2022-01-05T11:51:59.719424Z",
     "shell.execute_reply.started": "2022-01-05T11:25:03.584887Z"
    },
    "id": "Y7tZjkmAwucj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:705: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 100, 'min_samples_leaf': 1, 'n_estimators': 500}\n",
      "CPU times: user 1min 33s, sys: 1.45 s, total: 1min 35s\n",
      "Wall time: 26min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "parameter_RF = {\n",
    "    'min_samples_leaf': [1, 3],\n",
    "    'n_estimators': [500, 1000],\n",
    "    'max_depth': [50, 100]}\n",
    "\n",
    "rf = GridSearchCV(RandomForestClassifier(), parameter_RF, n_jobs=-1)\n",
    "rf.fit(X_train, y_train) \n",
    "\n",
    "rf_best_params = rf.best_params_\n",
    "print(\"Best parameters:\", rf_best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5017bb",
   "metadata": {
    "id": "htdnrJYEwucj"
   },
   "source": [
    "##### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce001bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T11:51:59.725117Z",
     "iopub.status.busy": "2022-01-05T11:51:59.724819Z",
     "iopub.status.idle": "2022-01-05T11:52:02.188371Z"
    },
    "id": "AgmYYywgwucj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[1374  460  270  205  326]\n",
      " [ 650 1035  349  277  321]\n",
      " [ 543  390  572  597  593]\n",
      " [ 359  312  414  872  650]\n",
      " [ 280  195  293  597 1301]] \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.43      0.52      0.47      2635\n",
      "     Class 1       0.43      0.39      0.41      2632\n",
      "     Class 2       0.30      0.21      0.25      2695\n",
      "     Class 3       0.34      0.33      0.34      2607\n",
      "     Class 4       0.41      0.49      0.44      2666\n",
      "\n",
      "    accuracy                           0.39     13235\n",
      "   macro avg       0.38      0.39      0.38     13235\n",
      "weighted avg       0.38      0.39      0.38     13235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_predicted = rf.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, rf_predicted), \"\\n\")\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, rf_predicted, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a84caa",
   "metadata": {},
   "source": [
    "In this case we obtain an accuracy of 40% that is slightly higher to the accuracy obtained from DTC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f08c94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T11:52:02.195779Z",
     "iopub.status.busy": "2022-01-05T11:52:02.195030Z",
     "iopub.status.idle": "2022-01-05T11:56:31.651722Z"
    },
    "id": "O-n2W_GAwucj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Accuracy:  0.33  Mean Accuracy: 0.25 +/- 0.16\n",
      "CPU times: user 94.4 ms, sys: 92.2 ms, total: 187 ms\n",
      "Wall time: 4min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators = rf_best_params['n_estimators'], \n",
    "                                min_samples_leaf = rf_best_params['min_samples_leaf'],\n",
    "                                max_depth = rf_best_params['max_depth'])\n",
    "\n",
    "rf_scores = cross_val_score(rf_clf, X, y, cv=5, n_jobs=-1)\n",
    "\n",
    "print(\"Max Accuracy: \", \"{:.2f}\".format(max(rf_scores)), \" Mean Accuracy:\", \"{:.2f}\".format(rf_scores.mean()), \"+/-\", \"{:.2f}\".format(rf_scores.std()*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368dcf96",
   "metadata": {},
   "source": [
    "As for Decision Tree and SVM the accuracy obtained is lower than the accuracy we printed in the classification report (25% instead of 39%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40de4cba",
   "metadata": {
    "id": "NUWlV7wfwucj"
   },
   "source": [
    "#### Multi Layer Perceptron Networks Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e98ed8c",
   "metadata": {},
   "source": [
    "MLPNs is a supervised machine learning algorithm which uses binary classifiers. The MLPN structure is composed of input, hidden and output layers, each layer fully connected to the next, with activation feeding forward. In MLPN we want our outputs to be as close to the right one as possible, and so we need to iteratively adjust the weights of each edge.\n",
    "\n",
    "In the following, we are going to show the necessary code to train a model and to obtain the best parameter for this model. Multi Layer Perceptron Networks Classifier need data scaled and normalized but as we said at the beginning of the section we decided to use scaled and normalized data and so we are ready to train our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555c9201",
   "metadata": {
    "id": "28Ac_scywuck"
   },
   "source": [
    "##### Hyper-Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "75dce601",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T11:10:55.576719Z",
     "iopub.status.busy": "2022-01-05T11:10:55.576352Z",
     "iopub.status.idle": "2022-01-05T11:14:50.996321Z",
     "shell.execute_reply": "2022-01-05T11:14:50.995177Z",
     "shell.execute_reply.started": "2022-01-05T11:10:55.576679Z"
    },
    "id": "kzNWKFtgwuck"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrea/Scaricati/ENTER/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/andrea/Scaricati/ENTER/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/andrea/Scaricati/ENTER/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/andrea/Scaricati/ENTER/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'tol': 0.001, 'solver': 'adam', 'hidden_layer_sizes': (30, 15, 10), 'alpha': 1e-05}\n",
      "CPU times: user 16 s, sys: 372 ms, total: 16.4 s\n",
      "Wall time: 50.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "parameter_MLP = {\n",
    "    'hidden_layer_sizes' : [(10, 5, 2), (20, 10, 5), (30, 15, 10)],\n",
    "    'alpha' : [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "    'solver' : ['lbfgs', 'sgd', 'adam'],\n",
    "    'tol': [1e-2, 1e-3, 1e-4]}\n",
    "\n",
    "mlpn = RandomizedSearchCV(MLPClassifier(), parameter_MLP, n_jobs=-1)\n",
    "mlpn.fit(X_train, y_train)\n",
    "\n",
    "mlp_best_params = mlpn.best_params_\n",
    "print(\"Best parameters:\", mlp_best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb7bcc2",
   "metadata": {},
   "source": [
    "As we can see, for some cases the algorithm does not converge, in fact it reaches the maximum of the iterations (by default it is 200). For this reason I have inserted the parameter <i> tol </i>, in order to increase the tolerance for optimization.\n",
    "\n",
    "Another option was to increase the number of iterations for MLPClassifier, however testing I found there was no improvement by taking the number of iterations up to 600."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6f2b0a",
   "metadata": {
    "id": "GV3LpL3lwuck"
   },
   "source": [
    "##### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "37dcf16b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T11:14:50.999254Z",
     "iopub.status.busy": "2022-01-05T11:14:50.998816Z",
     "iopub.status.idle": "2022-01-05T11:14:51.128995Z",
     "shell.execute_reply": "2022-01-05T11:14:51.128052Z",
     "shell.execute_reply.started": "2022-01-05T11:14:50.999198Z"
    },
    "id": "BdylSFHWwuck"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[1636  190  188  260  361]\n",
      " [1307  255  231  416  423]\n",
      " [ 931  214  295  699  556]\n",
      " [ 613  192  223  973  606]\n",
      " [ 497  152  134  821 1062]] \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.33      0.62      0.43      2635\n",
      "     Class 1       0.25      0.10      0.14      2632\n",
      "     Class 2       0.28      0.11      0.16      2695\n",
      "     Class 3       0.31      0.37      0.34      2607\n",
      "     Class 4       0.35      0.40      0.37      2666\n",
      "\n",
      "    accuracy                           0.32     13235\n",
      "   macro avg       0.30      0.32      0.29     13235\n",
      "weighted avg       0.30      0.32      0.29     13235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpl_predicted = mlpn.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, mpl_predicted), \"\\n\")\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, mpl_predicted, target_names = target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c4d129",
   "metadata": {},
   "source": [
    "For MLPNs we obtain an accuracy of 33%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5be203fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T11:14:51.131722Z",
     "iopub.status.busy": "2022-01-05T11:14:51.131026Z",
     "iopub.status.idle": "2022-01-05T11:16:25.100484Z",
     "shell.execute_reply": "2022-01-05T11:16:25.099793Z",
     "shell.execute_reply.started": "2022-01-05T11:14:51.131672Z"
    },
    "id": "eGBZe5hUwuck"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Accuracy:  0.31  Mean Accuracy: 0.29 +/- 0.07\n",
      "CPU times: user 207 ms, sys: 26.4 ms, total: 234 ms\n",
      "Wall time: 24.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mlpn_clf = MLPClassifier(solver = mlp_best_params['solver'],\n",
    "                    hidden_layer_sizes = mlp_best_params['hidden_layer_sizes'],\n",
    "                    alpha = mlp_best_params['alpha'],\n",
    "                    tol = mlp_best_params['tol'])\n",
    "\n",
    "mpl_scores = cross_val_score(mlpn_clf, X, y, cv=5, n_jobs=-1)\n",
    "print(\"Max Accuracy: \", \"{:.2f}\".format(max(mpl_scores)), \" Mean Accuracy:\", \"{:.2f}\".format(mpl_scores.mean()), \"+/-\", \"{:.2f}\".format(mpl_scores.std()*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c178ecb2",
   "metadata": {},
   "source": [
    "And as for all the other models, also for MLPN the accuracy obtained is lower than that of the classification report (29% instead of 33%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4455083e",
   "metadata": {
    "id": "eQAH0FRawuck"
   },
   "source": [
    "<hr>\n",
    "\n",
    "# 4. Summary\n",
    "Provide a summary discussion (in English) of your solution <b>(at least 500 words)</b> feel free to include plots figures and tables.\n",
    "\n",
    "<b>This is a mandatory step</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc76591",
   "metadata": {
    "id": "EczXV4aWwucl"
   },
   "source": [
    "#### Cleaning and Loading\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65f5387",
   "metadata": {
    "id": "GzFagd-byMRd"
   },
   "source": [
    "The first approach was to analyze the `OnlineNewsPopularity.csv` file, in which I found and corrected errors due to the use of incorrect characters, such as `\\n` in the middle of the lines or extra commas.\n",
    "After that I made a clean copy of the csv, and in uploading it via Pandas I also noticed that there were some missing values in the form of \" *n.a.*\" , which are not recognized as NaN values by Pandas, to solve this problem I used the `na_values` attribute of `pd.read_csv`.\n",
    "\n",
    "Subsequently I decided to delete the rows containing the Missing Value, this is because the percentage of the latter is about 1% of the total of the rows, so it is not advisable to apply the Imputer, which is used instead if the percentage of missing values is around 20%.\n",
    "\n",
    "Finally, since the `url` categorical feature has a number of different elements equal to the number of lines, I decided to delete it, as it is irrelevant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a300cfae",
   "metadata": {
    "id": "ZAwCSn0QyCkd"
   },
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ecd0c1",
   "metadata": {
    "id": "84UAihGzyPKH"
   },
   "source": [
    "Once I cleaned the DataSet I started the pre-processing phase, this is an important step since the data, in most cases, cannot be used directly by some learning algorithms without first being preprocessed.\n",
    "\n",
    "The preprocessing phase includes the **encoding** phase however there are no categorical features as I have decided to discard the `url` feature.\n",
    "\n",
    "First I **discretized** the target feature (`shares`) in 5 bins, to simplify the problem using the `KBinDiscretizer`, this is because the accuracy increases with a smaller number of classes as described on the paper (the delivery specifies that at least 5 bins must be used).\n",
    "\n",
    "So the next step was the class **balancing**, in particular the classes weren't too unbalanced but it is a necessary preprocessing step as some models, like Decision Tree, suffer if the classes are unbalanced.\n",
    "The option I decided to follow to manage class balancing was the `SMOTE` oversampling method, it is a better strategy than the subsampling and oversampling methods, as the former can lead to discarding useful samples and the latter can lead to overfitting. Specifically, the SMOTE method creates new instances of the minority class by forming a convex combination of neighboring samples.\n",
    "\n",
    "After performing the balancing, I proceeded to perform the **scaling**and **normalization** of the features, this is because some models, such as SVM, are more efficient if the data is resized.\n",
    "\n",
    "Finally I divided the dataset into **training** and **test** **sets** having dimensions 70 and 30 respectively, this is because a division into 80 - 20 takes much longer to run for the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e472e6aa",
   "metadata": {},
   "source": [
    "#### Dataset and Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49737f1",
   "metadata": {},
   "source": [
    "Subsequently I carried out the chapter of Dataset Analysis, using however the dataset not yet preprocessed (more precisely without balancing, scaling and normalization of the data), unlike the chapter of the Features Importance Analysis.\n",
    "Thanks to the data shown by the execution of the last phase, I have eliminated some features that were not very relevant from the analysis, in order to improve performance and speed up the execution of the learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fd34a7",
   "metadata": {
    "id": "YEIZ4EtGyGC0"
   },
   "source": [
    "\n",
    "#### Model Selection and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c903a7",
   "metadata": {
    "id": "CvQzfZ_T4RJ1"
   },
   "source": [
    "\n",
    "The models used for this phase are: **Decision Tree**, **SVM**, **Random Forest** (ensemble method) and **MLPN**.\n",
    "The same approach was adopted for each model, i.e. first of all the **hyper-parameters** were tuned with `GridSearchSV` function, then the models were trained with the training set, composed of scaled and normalized data, thus identifying the optimal parameters.\n",
    "\n",
    "After this I observe the results obtained with `confusion matrix` and `classification report`, from which it can be seen that \"Class 2\" is the most difficult to predict for all models, while the easiest classes to predict are those at the \"extremes\" (unpopular and popular), that is classes 0 and 4. This observation is also consistent with the results of paper [1], in which only two classes are used, that is, one for the most popular articles and another for those less.\n",
    "\n",
    "Finally, I use k-fold cross-validation, with k equal to 5, for each model, to find the best possible splitting of the dataset in train and test set, and print the average and maximum accuracy values found.\n",
    " \n",
    "In conclusion I compared the results of all the models and got more accuracy with the MLPNs classifier and SVMs reaching around 29%, followed by the Random Forest classifier 25% and the Decision Tree classifier (13%).\n",
    "\n",
    "I had also initially tried to test the various models using the non-scaled and non-normalized dataset, however I decided to discard this comparison because the execution took too long (except for the Decision Tree Classifier whose execution times were more or less similar).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1decf44e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
